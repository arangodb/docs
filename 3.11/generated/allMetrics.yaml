- name: arangodb_agency_append_hist
  introducedIn: "3.7.1"
  help: |
    Agency RAFT follower append time histogram.
  unit: ms
  type: histogram
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    This measures the time an Agency follower needs for individual
    append operations resulting from `AppendEntriesRPC` requests.
    Every event contributes a measurement to the histogram, which
    also exposes the number of events and the total sum of all
    measurements.
  threshold: |
    Normally these times should be clearly sub-second.
  troubleshoot: |
    If you see delays here, the Agents might not have enough IO bandwidth
    or might be overloaded. Try to provision more IOPS or more CPU capacity,
    potentially moving Agents to separate machines.

- name: arangodb_agency_cache_callback_number
  renamedFrom: arangodb_agency_cache_callback_count
  introducedIn: "3.8.0"
  help: |
    Current number of entries in Agency cache callbacks table.
  unit: number
  type: gauge
  category: Agency
  complexity: advanced
  exposedBy:
    - dbserver
    - coordinator
    - single
  description: |
    This reflects the current number of callbacks the local `AgencyCache`
    has registered.
    This metric was named `arangodb_agency_cache_callback_count` in
    previous versions of ArangoDB.
    Note that on single servers this metrics will only have a non-zero value
    in "active failover" deployment mode.
  threshold: |
    This number will usually be very low, something like 2 or 3.
  troubleshoot: |
    If this number is considerably higher, this should be investigated.
    Please contact support.

- name: arangodb_agency_callback_number
  renamedFrom: arangodb_agency_callback_count
  introducedIn: "3.8.0"
  help: |
    Current number of Agency callbacks registered.
  unit: number
  type: gauge
  category: Agency
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - single
  description: |
    This metric reflects the current number of Agency callbacks being
    registered, including Agency cache callbacks.
    This metric was named `arangodb_agency_callback_count` in previous versions
    of ArangoDB.
    Note that on single servers this metrics will only have a non-zero value
    in "active failover" deployment mode.
  threshold: |
    This number will usually be very low, something like 2 or 3.
  troubleshoot: |
    If this number is considerably higher, this should be investigated.
    Please contact support.

- name: arangodb_agency_callback_registered_total
  renamedFrom: arangodb_agency_callback_registered
  introducedIn: "3.8.0"
  help: |
    Total number of Agency callbacks ever registered.
  unit: number
  type: counter
  category: Agency
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - single
  description: |
    This metric was named `arangodb_agency_callback_registered` in previous versions
    of ArangoDB.
    Note that on single servers this metrics will only have a non-zero value
    in "active failover" deployment mode.

- name: arangodb_agency_client_lookup_table_size
  introducedIn: "3.6.11"
  help: |
    Current number of entries in Agency client id lookup table.
  unit: number
  type: gauge
  category: Agency
  complexity: advanced
  exposedBy:
    - agent
  description: |
    Current number of entries in Agency client id lookup table.
    The lookup table is used internally for Agency inquire operations
    and should be compacted at the same time when the Agency's in-memory
    log is compacted.

- name: arangodb_agency_commit_hist
  introducedIn: "3.7.1"
  help: |
    Agency RAFT commit histogram.
  unit: ms
  type: histogram
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Agency RAFT commit time histogram. Provides a distribution
    of commit times for all Agency write operations.

- name: arangodb_agency_compaction_hist
  introducedIn: "3.7.1"
  help: |
    Agency compaction time histogram.
  unit: ms
  type: histogram
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Agency compaction time histogram. Provides a distribution
    of Agency compaction run times. Compactions are triggered after
    `--agency.compaction-keep-size` entries have accumulated in the
    RAFT log.
  troubleshoot: |
    If compaction takes too long, it may be useful to reduce the number
    of log entries to keep in `--agency.compaction-keep-size`.

- name: arangodb_agency_local_commit_index
  introducedIn: "3.7.1"
  help: |
    This Agent's commit index.
  unit: number
  type: gauge
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    This Agent's commit index (i.e. the index until it has advanced in
    the Agency's RAFT protocol).

- name: arangodb_agency_log_size_bytes
  introducedIn: "3.6.9"
  help: |
    Agency replicated log size.
  unit: bytes
  type: gauge
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    Size of the Agency's in-memory part of replicated log in bytes.
    The replicated log will grow in memory until a certain number of
    log entries have been accumulated. Then the in-memory log will
    be compacted. The number of in-memory log entries to keep before
    log compaction kicks in can be controlled via the startup option
    `--agency.compaction-keep-size`.

- name: arangodb_agency_read_no_leader_total
  renamedFrom: arangodb_agency_read_no_leader
  introducedIn: "3.8.0"
  help: |
    Agency read operations with no leader or on followers.
  unit: number
  type: counter
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    Total number of Agency read operations with no leader or on followers.
  threshold: |
    This should normally not happen. If it happens regularly, the Agency
    is reelecting its leader often.
  troubleshoot: |
    The latency of the network between the Agents might be too high or
    the Agents may be overloaded. It might help to move Agent instances
    to separate machines.

- name: arangodb_agency_read_ok_total
  renamedFrom: arangodb_agency_read_ok
  introducedIn: "3.8.0"
  help: |
    Number of successful Agency read operations.
  unit: number
  type: counter
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    Number of Agency read operations which were successful (i.e. completed
    without any error). Successful reads can only be executed on the leader, so
    this metric is supposed to increase only on Agency leaders, but not on
    followers. Read requests that are executed on followers will be rejected
    and can be tracked via the metric `arangodb_agency_read_no_leader_total`.
    This metric was named `arangodb_agency_read_ok` in previous
    versions of ArangoDB.

- name: arangodb_agency_supervision_failed_server_total
  renamedFrom: arangodb_agency_supervision_failed_server_count
  introducedIn: "3.8.0"
  help: |
    Counter for FailedServer jobs.
  unit: number
  type: counter
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Counter for FailedServer jobs. This counter is increased whenever a
    supervision run encounters a failed server and starts a FailedServer job.
    This metric was named `arangodb_agency_supervision_failed_server_count`
    in previous versions of ArangoDB.
  threshold: |
    Many FailedServer jobs indicate frequent failures of DB-Servers. This
    is generally not good.
  troubleshoot: |
    Find the root cause of server failures. Overload and bad network latency
    can lead to misdetected server failures.

- name: arangodb_agency_supervision_runtime_msec
  introducedIn: "3.7.1"
  help: |
    Agency supervision runtime histogram.
  unit: ms
  type: histogram
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    Agency supervision runtime histogram. A new value is recorded for each
    run of the supervision.
  threshold: |
    The supervision runtime goes up linearly with the number of collections
    and shards.

- name: arangodb_agency_supervision_runtime_wait_for_replication_msec
  introducedIn: "3.7.1"
  help: |
    Agency supervision wait for replication time.
  unit: ms
  type: histogram
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Agency supervision replication time histogram. Whenever the Agency
    supervision carries out changes, it will write them to the leader's log
    and replicate the changes to followers. This metric provides a histogram
    of the time it took to replicate the supervision changes to followers.

- name: arangodb_agency_term
  introducedIn: "3.7.1"
  help: |
    Agency's term.
  unit: number
  type: gauge
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    The Agency's current term.
  threshold: |
    This number should usually not grow. If it does, the Agency is doing
    repeated reelections, which suggests overload or bad network latency
    between Agents.
  troubleshoot: |
    It might help to reduce network latency between Agents or move Agent
    instances to separate machines.

- name: arangodb_agency_write_hist
  introducedIn: "3.7.1"
  help: |
    Agency write time histogram.
  unit: ms
  type: histogram
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Agency write time histogram. This histogram provides the distribution
    of the times spent in Agency write operations, in milliseconds. This only
    includes the time required to write the data into the leader's log, but
    does not include the time required to replicate the writes to the followers.

- name: arangodb_agency_write_no_leader_total
  renamedFrom: arangodb_agency_write_no_leader
  introducedIn: "3.8.0"
  help: |
    Agency write operations with no leader or on followers.
  unit: number
  type: counter
  category: Agency
  complexity: medium
  exposedBy:
    - agent
  description: |
    Total number of Agency write operations with no leader or on followers.
  threshold: |
    This should normally not happen. If it happens regularly, the Agency
    is reelecting its leader often.
  troubleshoot: |
    The latency of the network between the Agents might be too high or
    the Agents may be overloaded. It might help to move Agent instances
    to separate machines.

- name: arangodb_agency_write_ok_total
  renamedFrom: arangodb_agency_write_ok
  introducedIn: "3.8.0"
  help: |
    Number of successful Agency write operations.
  unit: number
  type: counter
  category: Agency
  complexity: simple
  exposedBy:
    - agent
  description: |
    Number of Agency write operations which were successful (i.e. completed
    without any error). Successful writes can only be executed on the leader, so
    this metric is supposed to increase only on Agency leaders, but not on
    followers. Write requests that are executed on followers will be rejected
    and can be tracked via the metric `arangodb_agency_write_no_leader_total`.
    This metric was named `arangodb_agency_write_ok` in previous
    versions of ArangoDB.

- name: arangodb_agencycomm_request_time_msec
  introducedIn: "3.7.1"
  help: |
    Request time for Agency requests.
  unit: ms
  type: histogram
  category: Network
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    This histogram shows how long requests to the Agency took.
  threshold: |
    Usually, such requests should be relatively quick, mostly clearly
    sub-second.
  troubleshoot: |
    If the network or the Agents are overloaded, it can help to move
    Agent instances to separate machines.

- name: arangodb_aql_all_query_total
  renamedFrom: arangodb_aql_all_query
  introducedIn: "3.8.0"
  help: |
    Total number of AQL queries finished.
  unit: number
  type: counter
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of AQL queries finished.
    This metric was named `arangodb_aql_all_query` in previous
    versions of ArangoDB.

- name: arangodb_aql_current_query
  introducedIn: "3.8.0"
  help: |
    Current number of AQL queries executing.
  unit: number
  type: gauge
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Current number of AQL queries executing.

- name: arangodb_aql_global_memory_limit
  introducedIn: "3.8.0"
  help: |
    Total memory limit for all AQL queries combined.
  unit: bytes
  type: gauge
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total memory limit for all AQL queries combined, in bytes.
    If this value is reported as `0`, it means there is no total memory
    limit in place for AQL queries. The value can be adjusted by the setting
    the `--query.global-memory-limit` startup option.

- name: arangodb_aql_global_memory_usage
  introducedIn: "3.8.0"
  help: |
    Total memory usage of all AQL queries executing; granularity: 32768 bytes steps.
  unit: bytes
  type: gauge
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total memory usage of all AQL queries currently executing.
    The granularity of this metric is steps of 32768 bytes. The current
    memory usage of all AQL queries will be compared against the configured
    limit in the `--query.global-memory-limit` startup option.
    If the startup option has a value of `0`, then no global memory limit
    will be enforced. If the startup option has a non-zero value, queries
    will be aborted once the total query memory usage goes above the configured
    limit.

- name: arangodb_aql_global_query_memory_limit_reached_total
  introducedIn: "3.8.0"
  help: |
    Number of times the global query memory limit threshold was reached.
  unit: number
  type: counter
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of times the global query memory limit threshold was reached.
    This can happen if all running AQL queries in total try to use more memory than
    configured via the `--query.global-memory-limit` startup option.
    Every time this counter will increase, an AQL query will have aborted with a
    "resource limit exceeded" error.

- name: arangodb_aql_local_query_memory_limit_reached_total
  introducedIn: "3.8.0"
  help: |
    Number of times a local query memory limit threshold was reached.
  unit: number
  type: counter
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of times a local query memory limit threshold was reached, i.e.
    a single query tried to allocate more memory than configured in the query's
    `memoryLimit` attribute or the value configured via the startup option
    `--query.memory-limit`.
    Every time this counter will increase, an AQL query will have aborted with a
    "resource limit exceeded" error.

- name: arangodb_aql_query_time
  introducedIn: "3.6.10"
  help: |
    Execution time histogram for all AQL queries.
  unit: s
  type: histogram
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Execution time histogram for all AQL queries, in seconds.
    The histogram includes all slow queries.

- name: arangodb_aql_slow_query_time
  introducedIn: "3.6.10"
  help: |
    Execution time histogram for slow AQL queries.
  unit: s
  type: histogram
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Execution time histogram for slow AQL queries, in seconds.
    Queries are considered "slow" if their execution time is above the
    threshold configured in the startup options `--query.slow-threshold`
    or `--query.slow-streaming-threshold`, resp.

- name: arangodb_aql_total_query_time_msec_total
  renamedFrom: arangodb_aql_total_query_time_msec
  introducedIn: "3.8.0"
  help: |
    Total execution time of all AQL queries.
  unit: ms
  type: counter
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total execution time of all AQL queries, in milliseconds,
    including all slow queries.

- name: arangodb_client_connection_statistics_bytes_received
  introducedIn: "3.8.0"
  help: |
    Bytes received for a request.
  unit: bytes
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the received request sizes in bytes.

- name: arangodb_client_connection_statistics_bytes_sent
  introducedIn: "3.8.0"
  help: |
    Bytes sent for a request.
  unit: bytes
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the sent response sizes in bytes

- name: arangodb_client_connection_statistics_client_connections
  introducedIn: "3.6.1"
  help: |
    The number of client connections that are currently open.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of client connections that are currently open.
    Note: this metric considers only HTTP and HTTP/2 connections, but not VST
    connections.

- name: arangodb_client_connection_statistics_connection_time
  introducedIn: "3.8.0"
  help: |
    Total connection time of a client.
  unit: s
  type: histogram
  category: Statistics
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the connection's total lifetime, i.e., the time between the
    point when the connection was established until it was closed. Smaller
    numbers indicate that there is not a lot of load and/or that connections
    are not reused for multiple requests. Consider using keep-alive header
    or HTTP/2 or VST.

- name: arangodb_client_connection_statistics_io_time
  introducedIn: "3.8.0"
  help: |
    I/O time needed to answer a request.
  unit: number
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of I/O times needed to answer a request. This includes the time
    required to read the incoming request as well as the time required to send
    the response.

- name: arangodb_client_connection_statistics_queue_time
  introducedIn: "3.8.0"
  help: |
    Queueing time needed for requests.
  unit: s
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the time requests are spending on a queue waiting to be
    processed. The overwhelming majority of these times should be clearly
    sub-second.

- name: arangodb_client_connection_statistics_request_time
  introducedIn: "3.8.0"
  help: |
    Request time needed to answer a request.
  unit: s
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the time required to actually process a request. This does not
    include the time required to read the incoming request, the time the request
    is sitting on the queue, or the time required to send the response.

- name: arangodb_client_connection_statistics_total_time
  introducedIn: "3.8.0"
  help: |
    Total time needed to answer a request.
  unit: s
  type: histogram
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the total times required to process a request. This includes
    the time required to read the incoming request, the time the request is
    sitting in the queue, the time to actually process the request, and the
    time required to send the response.

- name: arangodb_collection_lock_acquisition_micros_total
  renamedFrom: arangodb_collection_lock_acquisition_micros
  introducedIn: "3.8.0"
  help: |
    Total amount of collection lock acquisition time.
  unit: us
  type: counter
  category: Transactions
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Total amount of time it took to acquire collection/shard locks for
    write operations, summed up for all collections/shards. Will not be increased
    for any read operations.
    The value is measured in microseconds.
  troubleshoot: |
    In case this value is considered too high, check if there are AQL queries
    or transactions that use exclusive locks on collections, and try to reduce them.
    Operations using exclusive locks may lock out other queries/transactions temporarily,
    which will lead to an increase in lock acquisition time.

- name: arangodb_collection_lock_acquisition_time
  introducedIn: "3.6.11"
  help: |
    Collection lock acquisition time histogram.
  unit: s
  type: histogram
  category: RocksDB
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Histogram of the collection/shard lock acquisition times. Locks will be acquired for
    all write operations, but not for read operations.
    The values here are measured in seconds.
  troubleshoot: |
    In case these values are considered too high, check if there are AQL queries
    or transactions that use exclusive locks on collections, and try to reduce them.
    Operations using exclusive locks may lock out other queries/transactions temporarily,
    which will lead to an increase in lock acquisition times.

- name: arangodb_collection_lock_sequential_mode_total
  renamedFrom: arangodb_collection_lock_sequential_mode
  introducedIn: "3.8.0"
  help: |
    Number of transactions using sequential locking of collections to avoid deadlocking.
  unit: number
  type: counter
  category: Transactions
  complexity: advanced
  exposedBy:
    - coordinator
  description: |
    Number of transactions using sequential locking of collections to avoid deadlocking.
    By default, a Coordinator will try to lock all shards of a collection in parallel.
    This approach is normally fast but can cause deadlocks with other transactions that
    lock the same shards in a different order. In case such a deadlock is detected, the
    Coordinator will abort the lock round and start a new one that locks all shards in
    sequential order. This will avoid deadlocks, but has a higher setup overhead.
  troubleshoot: |
    In case this value is increasing, check if there are AQL queries or transactions that
    use exclusive locks on collections, and try to reduce them.
    Operations using exclusive locks may lock out other queries/transactions temporarily,
    which will lead can lead to (temporary) deadlocks in case the queries/transactions
    are run on multiple shards on different servers.

- name: arangodb_collection_lock_timeouts_exclusive_total
  renamedFrom: arangodb_collection_lock_timeouts_exclusive
  introducedIn: "3.8.0"
  help: |
    Number of timeouts when trying to acquire collection exclusive locks.
  unit: number
  type: counter
  category: Transactions
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Number of timeouts when trying to acquire collection exclusive locks.
    This counter will be increased whenever an exclusive collection lock
    cannot be acquired within the configured lock timeout.
  troubleshoot: |
    In case this value is considered too high, check if there are AQL queries
    or transactions that use exclusive locks on collections, and try to reduce them.
    Operations using exclusive locks may lock out other queries/transactions temporarily,
    which can lead to other operations running into timeouts waiting for the same locks.

- name: arangodb_collection_lock_timeouts_write_total
  renamedFrom: arangodb_collection_lock_timeouts_write
  introducedIn: "3.8.0"
  help: |
    Number of timeouts when trying to acquire collection write locks.
  unit: number
  type: counter
  category: Transactions
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Number of timeouts when trying to acquire collection write locks.
    This counter will be increased whenever a collection write lock
    cannot be acquired within the configured lock timeout.
    This can only happen if writes on a collection are locked out by
    other operations on the collection that use an exclusive lock. Writes
    are not locked out by other, non-exclusively locked writes.
  troubleshoot: |
    In case this value is considered too high, check if there are AQL queries
    or transactions that use exclusive locks on collections, and try to reduce them.
    Operations using exclusive locks may lock out other queries/transactions temporarily,
    which can lead to other operations running into timeouts waiting for the same locks.

- name: arangodb_collection_truncate_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in collection truncate operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Total time spent in collection truncate operations, including both
    user-initiated truncate operations and truncate operations
    executed by the synchronous replication on followers.
    Note that this metric is only present when the command
    line option `--server.export-read-write-metrics` is set to `true`.

- name: arangodb_collection_truncates_replication_total
  renamedFrom: arangodb_collection_truncates_replication
  introducedIn: "3.8.0"
  help: |
    Total number of collection truncate operations by synchronous replication.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    Total number of collection truncate operations by synchronous
    replication on followers. Note that this metric is only present when the command
    line option `--server.export-read-write-metrics` is set to `true`.

- name: arangodb_collection_truncates_total
  renamedFrom: arangodb_collection_truncates
  introducedIn: "3.8.0"
  help: |
    Total number of collection truncate operations (excluding synchronous replication).
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total number of collection truncate operations on leaders (excluding synchronous
    replication). Note that this metric is only present when the command
    line option `--server.export-read-write-metrics` is set to `true`.

- name: arangodb_connection_pool_connections_created_total
  renamedFrom: arangodb_connection_pool_connections_created
  introducedIn: "3.8.0"
  help: |
    Total number of connections created for connection pool.
  unit: number
  type: counter
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Total number of connections created for connection pool. There are
    two pools, one for the Agency communication with label `AgencyComm`
    and one for the other cluster internal communication with label
    `ClusterComm`.
  threshold: |
    Because of idle timeouts, the total number of connections ever created
    will grow. However, under high load, most connections should usually
    be reused and a fast growth of this number can indicate underlying
    connectivity issues.

- name: arangodb_connection_pool_connections_current
  renamedFrom: arangodb_connection_connections_current
  introducedIn: "3.8.0"
  help: |
    Current number of connections in pool.
  unit: number
  type: gauge
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Current number of connections in pool. There are two pools, one for the
    Agency communication with label `AgencyComm` and one for the other
    cluster internal communication with label `ClusterComm`.
  threshold: |
    Normally, one should not see an excessive amount of open connections
    here, unless a very high amount of operations happens concurrently.

- name: arangodb_connection_pool_lease_time_hist
  introducedIn: "3.8.0"
  help: |
    Time to lease a connection from the connection pool.
  unit: ms
  type: histogram
  category: Connectivity
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Time to lease a connection from the connection pool. There are two pools,
    one for the Agency communication with label `AgencyComm` and one for
    the other cluster internal communication with label `ClusterComm`.
  threshold: |
    Leasing connections from the pool should be fast, unless a new connection
    has to be formed, which can easily take (in particular with TLS) several
    milliseconds. If times are a lot higher, then some underlying network
    problem might be there.

- name: arangodb_connection_pool_leases_failed_total
  renamedFrom: arangodb_connection_pool_leases_failed
  introducedIn: "3.8.0"
  help: |
    Total number of failed connection leases.
  unit: number
  type: counter
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Total number of failed connection leases. There are two pools, one for
    the Agency communication with label `AgencyComm` and one for the other
    cluster internal communication with label `ClusterComm`.
  threshold: |
    A failed lease can happen if a connection has been terminated
    by some idle timeout or if it is already in use by some other request.
    Since this can happen under concurrent load, failed leases are not
    actually very worrying.

- name: arangodb_connection_pool_leases_successful_total
  renamedFrom: arangodb_connection_leases_successful
  introducedIn: "3.8.0"
  help: |
    Total number of successful connection leases from connection pool.
  unit: number
  type: counter
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Total number of successful connection leases from connection pool.
    There are two pools, one for the Agency communication with label
    `AgencyComm` and one for the other cluster internal communication with
    label `ClusterComm`.
  threshold: |
    It is normal that this number is growing rapidly when there is any
    kind of activity in the cluster.

- name: arangodb_dirty_read_queries_total
  introducedIn: "3.10.0"
  help: |
    Number of AQL queries which have been executed with dirty reads.
  unit: number
  type: counter
  category: AQL
  complexity: simple
  exposedBy:
    - coordinator
  description: |
    This counter exposes the number of AQL queries which have been executed
    with "dirty reads". A dirty read is one which may also use follower shards
    and not only leader shards. Note that it is the transaction in the context
    of which the AQL runs which determines, if dirty reads are allowed.

- name: arangodb_dirty_read_transactions_total
  introducedIn: "3.10.0"
  help: |
    Number of read transactions, which are allowed to do dirty reads.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of read-only transactions, which allow for dirty reads
    (read from followers). This metric will only be collected for
    transactions on Coordinators in a cluster. Other instances may expose
    the value as 0.
  

- name: arangodb_document_insert_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in document insert operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total time spent in document insert operations, including both
    user-initiated insert operations and insert operations executed by
    the synchronous replication on followers. This metric
    is only present if the option `--server.export-read-write-metrics` is set
    to `true`.

- name: arangodb_document_read_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in document read-by-primary-key operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - agent
  description: |
    Total time spent in document read-by-primary-key operations. This metric
    is only present if the option `--server.export-read-write-metrics` is set
    to `true`.

- name: arangodb_document_remove_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in document remove operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total time spent in document replace operations, including both
    user-initiated replace operations and replace operations executed by
    the synchronous replication on followers. This metric
    is only present if the option `--server.export-read-write-metrics` is set
    to `true`.

- name: arangodb_document_replace_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in document replace operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total time spent in document replace operations, including both
    user-initiated replace operations and replace operations executed by
    the synchronous replication on followers. This metric
    is only present if the option `--server.export-read-write-metrics` is set
    to `true`.

- name: arangodb_document_update_time
  introducedIn: "3.8.0"
  help: |
    Total time spent in document update operations.
  unit: s
  type: histogram
  category: Transactions
  complexity: simple
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total time spent in document update operations, including both
    user-initiated update operations and update operations executed by
    the synchronous replication on followers. This metric
    is only present if the option `--server.export-read-write-metrics` is set
    to `true`.

- name: arangodb_document_writes_replication_total
  renamedFrom: arangodb_document_writes_replication
  introducedIn: "3.8.0"
  help: |
    Total number of document write operations by synchronous replication.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    Total number of document write operations by synchronous replication.
    This metric is only present if the option
    `--server.export-read-write-metrics` is set to `true`.
    Total number of document write operations (insert, update, replace, remove)
    executed by the synchronous replication on followers.
    This metric is only present if the option `--server.export-read-write-metrics`
    is set to `true`.

- name: arangodb_document_writes_total
  renamedFrom: arangodb_document_writes
  introducedIn: "3.8.0"
  help: |
    Total number of document write operations (excluding synchronous replication).
  unit: number
  type: counter
  category: Transactions
  complexity: medium
  exposedBy:
    - agent
    - dbserver
    - single
  description: |
    Total number of document write operations (insert, update, replace, remove) on
    leaders, excluding writes by the synchronous replication on followers.
    This metric is only present if the option `--server.export-read-write-metrics`
    is set to `true`.

- name: arangodb_dropped_followers_total
  renamedFrom: arangodb_dropped_followers_count
  introducedIn: "3.8.0"
  help: |
    Number of drop-follower events.
  unit: number
  type: counter
  category: Health
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Total number of drop-follower events. This metric is increased on leaders
    whenever a write operation cannot be replicated to a follower during
    synchronous replication, and it would be unsafe in terms of data consistency
    to keep that follower.
    This metric was named `arangodb_dropped_followers_count` in previous
    versions of ArangoDB.
  threshold: |
    Usually, drop-follower events should only happen if servers are
    restarted or if there are real problems on followers.

- name: arangodb_heartbeat_failures_total
  renamedFrom: arangodb_heartbeat_failures
  introducedIn: "3.8.0"
  help: |
    Total number of failed heartbeat transmissions.
  unit: number
  type: counter
  category: Health
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - single
  description: |
    Total number of failed heartbeat transmissions.
    Servers in a cluster periodically send their heartbeats to
    the Agency to report their own liveliness. This counter gets
    increased whenever sending such a heartbeat fails. In the single
    server, this counter is only used in active failover mode.
  threshold: |
    It is a bad sign for health if heartbeat transmissions fail. This can
    lead to failover actions which are ultimately bad for the service.
  troubleshoot: |
    This can be a sign of overload or of bad network connectivity. Potentially
    move the Agent instances to separate machines.

- name: arangodb_heartbeat_send_time_msec
  introducedIn: "3.7.1"
  help: |
    Time required to send a heartbeat.
  unit: ms
  type: histogram
  category: Health
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - single
  description: |
    Histogram of times required to send heartbeats. For every heartbeat
    sent the time is measured and an event is put into the histogram.
    In the single server, this counter is only used in active failover mode.
  threshold: |
    It is a bad sign for health if heartbeat transmissions are not fast.
    If there are heartbeats which frequently take longer than a few hundred
    milliseconds, or even seconds, this can eventually lead to failover actions
    which are ultimately bad for the service.
  troubleshoot: |
    High heartbeat send times can be a sign of overload or of bad network
    connectivity. Potentially move the Agent instances to separate machines.

- name: arangodb_http2_connections_total
  introducedIn: "3.7.15"
  help: |
    Total number of HTTP/2 connections accepted.
  unit: number
  type: counter
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of connections accepted for HTTP/2, this can be upgraded
    connections from HTTP/1.1 or connections negotiated to be HTTP/2 during
    the TLS handshake.

- name: arangodb_http_request_statistics_async_requests_total
  renamedFrom: arangodb_http_request_statistics_async_requests
  introducedIn: "3.8.0"
  help: |
    Number of asynchronously executed HTTP requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of **asynchronous** HTTP (or VST)
    requests which have hit this particular instance of `arangod`. Asynchronous
    refers to the fact that the response is not sent with the HTTP response,
    but is rather queried separately using the `/_api/jobs` API.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_delete_requests_total
  renamedFrom: arangodb_http_request_statistics_http_delete_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP DELETE requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **DELETE**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_get_requests_total
  renamedFrom: arangodb_http_request_statistics_http_get_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP GET requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **GET**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_head_requests_total
  renamedFrom: arangodb_http_request_statistics_http_head_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP HEAD requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **HEAD**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_options_requests_total
  renamedFrom: arangodb_http_request_statistics_http_options_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP OPTIONS requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **OPTIONS**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_patch_requests_total
  renamedFrom: arangodb_http_request_statistics_http_patch_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP PATCH requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **PATCH**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_post_requests_total
  renamedFrom: arangodb_http_request_statistics_http_post_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP POST requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **POST**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_http_put_requests_total
  renamedFrom: arangodb_http_request_statistics_http_put_requests
  introducedIn: "3.8.0"
  help: |
    Number of HTTP PUT requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **PUT**
    requests which have hit this particular instance of `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_other_http_requests_total
  renamedFrom: arangodb_http_request_statistics_other_http_requests
  introducedIn: "3.8.0"
  help: |
    Number of other HTTP requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) **other**
    or **ILLEGAL** requests which have hit this particular instance of
    `arangod`. These are all requests, which are not one of the following:
    `DELETE`, `GET`, `HEAD`, `POST`, `PUT`, `OPTIONS`, `PATCH`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_superuser_requests_total
  renamedFrom: arangodb_http_request_statistics_superuser_requests
  introducedIn: "3.8.0"
  help: |
    Total number of HTTP requests executed by superuser/JWT.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST)
    requests that have been authenticated with the JWT superuser token,
    which have hit this particular instance of
    `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_total_requests_total
  renamedFrom: arangodb_http_request_statistics_total_requests
  introducedIn: "3.8.0"
  help: |
    Total number of HTTP requests.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) requests which
    have hit this particular instance of `arangod`. Note that this counter
    is ever growing during the lifetime of the `arangod` process. However,
    when the process is restarted, it starts from scratch. In the Grafana
    dashboards, it is usually visualized as a rate per second, averaged
    with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_http_request_statistics_user_requests_total
  renamedFrom: arangodb_http_request_statistics_user_requests
  introducedIn: "3.8.0"
  help: |
    Total number of HTTP requests executed by user clients.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of HTTP (or VST) requests
    that have been authenticated for some user (as opposed to with the
    JWT superuser token), which have hit this particular instance of
    `arangod`.
    
    Note that this counter is ever growing during the lifetime of the
    `arangod` process. However, when the process is restarted, it starts
    from scratch. In the Grafana dashboards, it is usually visualized as a
    rate per second, averaged with a sliding window of a minute.
  threshold: |
    This metrics reflects the performance of an instance in a certain way.
    Note that your mileage may vary according to available resources as well
    as to complexity of the requests the client sends.

- name: arangodb_intermediate_commits_total
  renamedFrom: arangodb_intermediate_commits
  introducedIn: "3.8.0"
  help: |
    Number of intermediate commits performed in transactions.
  unit: number
  type: counter
  category: Statistics
  complexity: medium
  exposedBy:
    - dbserver
    - single
  description: |
    Number of intermediate commits performed in transactions.
    An intermediate commit happens if a logical transaction needs to be
    split into multiple physical transaction because of the volume of data
    handled in the transaction. The thresholds for when to perform an
    intermediate commit can be controlled by startup options
    `--rocksdb.intermediate-commit-count` (number of write operations after
    which an intermediate commit is triggered) and `--rocksdb.intermediate-commit-size`
    (cumulated size of write operations after which an intermediate commit is triggered).
    The values can also be overridden for individual transactions.
    This metric was named `arangodb_intermediate_commits` in previous
    versions of ArangoDb.
  troubleshoot: |
    If this value is non-zero, it doesn't necessarily indicate a problem. It can
    happen for large transactions and large data-loading jobs. However, as modifications
    performed by intermediate commits are persisted and cannot simply be rolled back in
    memory, it should be monitored whether the intermediate commits only happen for
    operations where they are expected. If they also happen for operations that are
    supposed to be atomic, then the intermediate commit size and count parameters need
    to be adjusted, or larger operations should be broken up into smaller ones in the
    client application.

- name: arangodb_ioheartbeat_delays_total
  introducedIn: "3.8.7"
  help: |
    Number of delays in the io heartbeat test.
  unit: number
  type: counter
  category: Health
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This counter is increased whenever the io heartbeat encounters a delay
    of at least 1s when writing a small file to the database directory,
    reading it and then removing it again.
    This test is done periodically to ensure that the underlying volume is
    usable and performs reasonably well. The test can be switched off
    explicitly with the flag `--database.io-heartbeat=false`, but the
    default is `true`. Furthermore, every such failure leads to a line in
    the log at INFO level for the `ENGINES` topic.

- name: arangodb_ioheartbeat_duration
  introducedIn: "3.8.7"
  help: |
    Histogram of execution times of a single IO heartbeat check.
  unit: us
  type: histogram
  category: Health
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This histogram is updated whenever the io heartbeat runs its test in
    the database directory. It writes a small file, syncs it to durable
    storage, reads it, and then unlinks the file again. This test is done
    periodically to ensure that the underlying volume is usable and performs
    reasonably well. The test can be switched off explicitly with the flag
    `--database.io-heartbeat=false`, but the default is `true`.

- name: arangodb_ioheartbeat_failures_total
  introducedIn: "3.8.7"
  help: |
    Number of failures in the io heartbeat test.
  unit: number
  type: counter
  category: Health
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This counter is increased whenever the io heartbeat encounters a problem
    when writing a small file to the database directory, reading it and then
    removing it again. This test is done
    periodically to ensure that the underlying volume is usable. The test can
    be switched off explicitly with the flag `--database.io-heartbeat=false`,
    but the default is `true`. Furthermore, every such failure leads to a
    line in the log at INFO level for the `ENGINES` topic.

- name: arangodb_license_expires
  introducedIn: "3.9.1"
  help: |
    This instance's license expiry in days.
  unit: number
  type: gauge
  category: License
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
  description: |
    This instance's remaining license validity time.

- name: arangodb_load_current_runtime
  introducedIn: "3.7.1"
  help: |
    `Current` loading runtimes.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Histogram of `Current` loading runtimes, i.e. the runtimes
    of the `ClusterInfo::loadCurrent` internal method. Provides a
    distribution of all loading times for the `Current`
    section of the Agency data. The `Current` section gets
    loaded on server startup, and then gets reloaded on servers
    only for any databases in which there have been recent structural
    changes (i.e. DDL changes).
  troubleshoot: |
    In case this histogram contains very high loading times, this
    may be due to using many collections or many shards inside a
    database for which there are often structural changes. It then
    may make sense to reduce the number of collections or number
    of shards. Note that this can have other effects, so it requires
    an informed decision.

- name: arangodb_load_plan_runtime
  introducedIn: "3.7.1"
  help: |
    `Plan` loading runtimes.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
  description: |
    Histogram of `Plan` loading runtimes, i.e. the runtimes
    of the `ClusterInfo::loadPlan` internal method. Provides a
    distribution of all loading times for the `Plan`
    section of the Agency data. The `Plan` section normally gets
    loaded on server startup, and then gets reloaded on servers
    only for any databases in which there have been recent structural
    changes (i.e. DDL changes).
  troubleshoot: |
    In case this histogram contains very high loading times, this
    may be due to using many collections or many shards inside a
    database for which there are often structural changes. It then
    may make sense to reduce the number of collections or number
    of shards. Note that this can have other effects, so it requires
    an informed decision.

- name: arangodb_logger_errors_total
  introducedIn: "3.9.0"
  help: |
    Total number of errors logged.
  unit: number
  type: counter
  category: Errors
  complexity: simple
  exposedBy:
    - agent
    - coordinator
    - dbserver
    - single
  description: |
    Total number of errors (ERR messages) logged by the logger. 
  
    If a problem is encountered which is fatal to some operation, but not for
    the service or the application as a whole, then an _error is logged.
  
    Reasons for log entries of this severity are for example include missing
    data, inability to open required files, incorrect connection strings,
    missing services.
  
    If an error is logged then it should be taken seriously as it may require 
    user intervention to solve.

- name: arangodb_logger_warnings_total
  introducedIn: "3.9.0"
  help: |
    Total number of warnings logged.
  unit: number
  type: counter
  category: Errors
  complexity: simple
  exposedBy:
    - agent
    - coordinator
    - dbserver
    - single
  description: |
    Total number of warnings (WARN messages) logged by the logger, 
    including startup warnings.
  
    Warnings might indicate problems, or might not. For example, 
    expected transient environmental conditions such as short loss of 
    network or database connectivity are logged as warnings, not errors. 

- name: arangodb_maintenance_action_done_total
  renamedFrom: arangodb_maintenance_action_done_counter
  introducedIn: "3.8.0"
  help: |
    Counter of actions that are done and have been removed from the registry.
  unit: number
  type: counter
  category: Maintenance
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    This metric counts the number of actions that are done and have been removed.

- name: arangodb_maintenance_action_duplicate_total
  renamedFrom: arangodb_maintenance_action_duplicate_counter
  introducedIn: "3.8.0"
  help: |
    Counter of actions that have been discarded because of a duplicate.
  unit: number
  type: counter
  category: Maintenance
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    This metric counts the number of actions that have been created but found to
    be a duplicate of a already queued action.

- name: arangodb_maintenance_action_failure_total
  renamedFrom: arangodb_maintenance_action_failure_counter
  introducedIn: "3.8.0"
  help: |
    Failure counter for the maintenance actions.
  unit: number
  type: counter
  category: Maintenance
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    Those action can fail for different reasons. This metric counts the failed
    actions and can thus provide hints to investigate a malfunction.

- name: arangodb_maintenance_action_queue_time_msec
  introducedIn: "3.7.1"
  help: |
    Time spent in the queue before execution for maintenance actions.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    This metric tracks the time actions spend waiting in the queue in a histogram.

- name: arangodb_maintenance_action_registered_total
  renamedFrom: arangodb_maintenance_action_registered_counter
  introducedIn: "3.8.0"
  help: |
    Counter of actions that have been registered in the action registry.
  unit: number
  type: counter
  category: Maintenance
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    This metric counts the number of actions that are queued or active.

- name: arangodb_maintenance_action_runtime_msec
  introducedIn: "3.7.1"
  help: |
    Time spent executing a maintenance action.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. Actions are created, registered, queued and executed.
    Once they are done they will eventually be removed.
  
    This metric tracks the time actions spend executing in a histogram.

- name: arangodb_maintenance_agency_sync_runtime_msec
  introducedIn: "3.7.1"
  help: |
    Total time spent on Agency sync.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. To identify the target state differences in the meta
    data store provided by the Agency are investigated and local changes are
    reported. This process is called Agency sync and is executed in regular
    intervals.
  
    This metric tracks the runtime of individual Agency syncs in a histogram.
    During DDL operations the runtime can increase but should generally be below
    1s.

- name: arangodb_maintenance_phase1_runtime_msec
  introducedIn: "3.7.1"
  help: |
    Maintenance Phase 1 runtime histogram.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. To identify the target state differences in the meta
    data store provided by the Agency are investigated and local changes are
    reported. This process is called Agency sync and is executed in regular
    intervals.
  
    This metric tracks the runtime of phase1 of an Agency sync. Phase1 calculates
    the difference between the local and the target state.

- name: arangodb_maintenance_phase2_runtime_msec
  introducedIn: "3.7.1"
  help: |
    Maintenance Phase 2 runtime histogram.
  unit: ms
  type: histogram
  category: Maintenance
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Database servers execute reconciliation actions to let the cluster converge
    to the desired state. To identify the target state differences in the meta
    data store provided by the Agency are investigated and local changes are
    reported. This process is called Agency sync and is executed in regular
    intervals.
  
    This metric tracks the runtime of phase2 of an Agency sync. Phase2 calculates
    what actions to execute given the difference of the local and target state.

- name: arangodb_network_forwarded_requests_total
  renamedFrom: arangodb_network_forwarded_requests
  introducedIn: "3.8.0"
  help: |
    Number of requests forwarded to another Coordinator.
  unit: number
  type: counter
  category: Network
  complexity: simple
  exposedBy:
    - coordinator
  description: |
    Number of requests forwarded to another Coordinator.
    Request forwarding can happen in load-balanced setups,
    when one Coordinator receives and forwards requests
    that can only be handled by a different Coordinator.
    This includes requests for streaming transactions,
    AQL, query cursors, Pregel jobs and some others.

- name: arangodb_network_request_duration_as_percentage_of_timeout
  introducedIn: "3.8.0"
  help: |
    Internal request round-trip time as a percentage of timeout.
  unit: percentage
  type: gauge
  category: Network
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Histogram providing the round-trip time of internal requests as a percentage
    of the respective request timeout.
    This metric will provide values between 0 and 100.
  troubleshoot: |
    High values indicate problems with requests that have timed out or have not been
    far away from running into timeouts. If many requests timeout, this is normally
    a symptom of overload. This can normally be mitigated by reducing the workload
    or adjusting the type of operations that are causing the high response times.
    If the timeouts happen as a result of not enough processing power, it may be
    useful to scale up the cluster.

- name: arangodb_network_request_timeouts_total
  renamedFrom: arangodb_network_request_timeouts
  introducedIn: "3.8.0"
  help: |
    Number of internal requests that have timed out.
  unit: number
  type: counter
  category: Network
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Number of internal requests that have timed out. This metric is increased
    whenever any cluster-internal request executed in the underlying connection
    pool runs into a timeout.
  troubleshoot: |
    Request timeouts can be caused by the destination servers being overloaded
    and thus slow to respond, or by network errors. If this counter increases,
    it is advised to check network connectivity and server loads.

- name: arangodb_network_requests_in_flight
  introducedIn: "3.8.0"
  help: |
    Number of outgoing internal requests in flight.
  unit: number
  type: gauge
  category: Network
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Number of outgoing internal requests in flight. This metric is increased
    whenever any cluster-internal request is about to be sent via the underlying
    connection pool, and is decreased whenever a response for such a request is
    received or the request runs into a timeout.
    This metric provides an estimate of the fan-out of operations. For example,
    a user operation on a collection with a single shard will normally lead to
    a single internal request (plus replication), whereas an operation on a
    collection with 10 shards may lead to a fan-out of 10 (plus replication).

- name: arangodb_potentially_dirty_document_reads_total
  introducedIn: "3.10.0"
  help: |
    Number of document reads which have been executed with dirty reads.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
  description: |
    This counter exposes the number of document reads (single or batch to
    shards in the cluster) which have been executed with "dirty reads".
    A dirty read is one which may also use follower shards and not only
    leader shards. Note that it is the transaction in the context of which
    the read runs which determines, if dirty reads are allowed.

- name: arangodb_pregel_conductors_loading_number
  introducedIn: "3.10.0"
  help: |
    Number of loading Pregel conductors.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of loading Pregel conductors.

- name: arangodb_pregel_conductors_number
  introducedIn: "3.10.0"
  help: |
    Number of Pregel conductors.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of Pregel conductors.

- name: arangodb_pregel_conductors_running_number
  introducedIn: "3.10.0"
  help: |
    Number of running Pregel conductors.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of running Pregel conductors.

- name: arangodb_pregel_conductors_storing_number
  introducedIn: "3.10.0"
  help: |
    Number of storing Pregel conductors.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of storing Pregel conductors.

- name: arangodb_pregel_graph_memory_bytes_number
  introducedIn: "3.10.0"
  help: |
    Memory allocated by Pregel for graph storage.
  unit: bytes
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    The number of bytes allocated by Pregel.

- name: arangodb_pregel_messages_received_total
  introducedIn: "3.10.0"
  help: |
    Number of messages received by Pregel.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    The number of messages received by Pregel.

- name: arangodb_pregel_messages_sent_total
  introducedIn: "3.10.0"
  help: |
    Number of messages sent by Pregel.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of messages sent by Pregel.

- name: arangodb_pregel_threads_number
  introducedIn: "3.10.0"
  help: |
    Number of threads running for Pregel.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of threads running for Pregel.

- name: arangodb_pregel_workers_loading_number
  introducedIn: "3.10.0"
  help: |
    Number of loading Pregel workers.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of loading Pregel workers.

- name: arangodb_pregel_workers_number
  introducedIn: "3.10.0"
  help: |
    Number of Pregel workers.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of Pregel Workers.

- name: arangodb_pregel_workers_running_number
  introducedIn: "3.10.0"
  help: |
    Number of running Pregel workers.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of running Pregel workers.

- name: arangodb_pregel_workers_storing_number
  introducedIn: "3.10.0"
  help: |
    Number of storing Pregel workers.
  unit: number
  type: gauge
  category: Pregel
  complexity: simple
  exposedBy:
    - dbserver
    - single
    - coordinator
  description: |
    Number of storing Pregel workers.

- name: arangodb_process_statistics_major_page_faults_total
  renamedFrom: arangodb_process_statistics_major_page_faults
  introducedIn: "3.8.0"
  help: |
    Number of major page faults.
  unit: number
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    On Windows, this figure contains the total number of page faults.
    On other system, this figure contains the number of major faults the
    process has made which have required loading a memory page from disk.
  troubleshooting: |
    If the rate of this is high, i.e. it increases fast, it could be an indication
    that the memory usage is too high, or the memory is too low, or paging is done
    too aggressively (for Linux, this see sysctl and vm.swappiness).

- name: arangodb_process_statistics_minor_page_faults_total
  renamedFrom: arangodb_process_statistics_minor_page_faults
  introducedIn: "3.8.0"
  help: |
    Number of minor page faults.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of minor faults the process has made which have not required
    loading a memory page from disk. This figure is not reported on Windows.

- name: arangodb_process_statistics_number_of_threads
  introducedIn: "3.6.1"
  help: |
    Number of threads.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of threads in the arangod process.

- name: arangodb_process_statistics_resident_set_size
  introducedIn: "3.6.1"
  help: |
    Resident set size.
  unit: bytes
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The total size of the number of pages the process has in real memory.
    This is just the pages which count toward text, data, or stack space.
    This does not include pages which have not been demand-loaded in, or
    which are swapped out. The resident set size is reported in bytes.

- name: arangodb_process_statistics_resident_set_size_percent
  introducedIn: "3.6.1"
  help: |
    Resident set size as fraction of system memory.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The relative size of the number of pages the process has in real
    memory compared to system memory. This is just the pages which count
    toward text, data, or stack space. This does not include pages which
    have not been demand-loaded in, or which are swapped out. The value is a
    ratio between 0.00 and 1.00.
  threshold: |
    This value can be consistently relatively high, even when not under load,
    due to different caches like the RocksDB block cache or the edge cache. There
    should be some safety margin left, so it should not get too close to 1.
  troubleshooting: |
    If the memory is nearly full, this can lead to performance degradation, errors
    because queries can't be executed, or the process being killed by the
    operating system to free memory. This can be mitigated by adding more memory,
    decreasing the size of caches if they aren't much needed, or restricting the
    amount of memory AQL queries may use.

- name: arangodb_process_statistics_system_time
  introducedIn: "3.6.1"
  help: |
    Process system time.
  unit: s
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Amount of time that this process has been scheduled in kernel mode,
    measured in seconds.
  threshold: |
    This metric can vary significantly dependent on the workload. If the rate is
    consistently very high, it could be an indication of some problem.
  troubleshooting: |
    There are many possible reasons for this, and specific advice cannot be given
    here. Examples can be costly or inefficient queries being executed, or just
    that the machine's performance is not sufficient for the tasks.

- name: arangodb_process_statistics_user_time
  introducedIn: "3.6.1"
  help: |
    Process user time.
  unit: s
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Amount of time that this process has been scheduled in user mode,
    measured in seconds.
  threshold: |
    This metric can vary significantly dependent on the workload. If the rate is
    consistently very high, it could be an indication of some problem.
  troubleshooting: |
    There are many possible reasons for this, and specific advice cannot be given
    here. Examples can be costly or inefficient queries being executed, or just
    that the machine's performance is not sufficient for the tasks.

- name: arangodb_process_statistics_virtual_memory_size
  introducedIn: "3.6.1"
  help: |
    Virtual memory size.
  unit: bytes
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    On Windows, this figure contains the total amount of memory that the
    memory manager has committed for the arangod process. On other systems,
    this figure contains the size of the virtual memory the process is
    using.

- name: arangodb_read_transactions_total
  introducedIn: "3.8.2"
  help: |
    Number of read transactions.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of read-only transactions. In the cluster, this metric will
    be collected separately for transactions on Coordinators and the
    transaction counterparts on leaders and followers.
  

- name: arangodb_refused_followers_total
  renamedFrom: arangodb_refused_followers_count
  introducedIn: "3.8.0"
  help: |
    Number of refusal answers from a follower during synchronous replication.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Number of refusal answers from a follower during synchronous replication.
    A refusal answer will only be sent by a follower if the follower is under
    the impression that the replication request was not sent by the current
    shard leader. This can happen if replication requests to the follower are
    delayed or the follower is slow to process incoming requests and there was
    a leader change for the shard.
    If such a refusal answer is received by the shard leader, it will drop the
    follower from the list of followers.
    This metrics was named `arangodb_refused_followers_count` in previous
    versions of ArangoDB.
  threshold: |
    Usually, refusal answers only occur if request processing on followers is
    delayed and there was a recent leadership change. This should not be a
    common case and normally indicates a problem with the setup or with the load.

- name: arangodb_replication_cluster_inventory_requests_total
  renamedFrom: arangodb_replication_cluster_inventory_requests
  introducedIn: "3.8.0"
  help: |
    (DC-2-DC only) Number of times the database and collection overviews have been requested.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - coordinator
  description: |
    When using a DC-2-DC configuration of ArangoDB this metric is active on both data-centers.
    It indicates that the follower data-center periodically matches the available databases and collections
    in order to mirror them. If no DC-2-DC is set up this value is expected to be 0.
  troubleshoot: |
    If you have a DC-2-DC installation, and this metric stays constant over a longer period of time in any of the two data centers
    this indicates that the follower data center is not properly connected anymore.
    The issue most likely is within the sync process on either of the two data-centers as they do not compare their inventory anymore.
    This gives no information about the healthiness of the ArangoDB cluster itself, please check other metrics for this.

- name: arangodb_replication_dump_apply_time_total
  renamedFrom: arangodb_replication_dump_apply_time
  introducedIn: "3.8.0"
  help: |
    Accumulated time needed to apply asynchronously replicated data on initial synchronization of shards.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    Measures the time required to clone the existing leader copy of the data onto a new replica shard.
    Will only be measured on the follower server. This time is expected to increase whenever new followers
    are created, e.g. increasing replication factor, shard redistribution.
  troubleshoot: |
    This metric measures as typical operation to keep the cluster resilient, so no reaction is required.
    In a stable cluster situation (no outages, no collection modification) this metric should also be stable.

- name: arangodb_replication_dump_bytes_received_total
  renamedFrom: arangodb_replication_dump_bytes_received
  introducedIn: "3.8.0"
  help: |
    Total number of bytes replicated in initial asynchronous phase.
  unit: bytes
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    During initial replication the existing data from the leader is copied asynchronously
    over to new shards. The amount of requests required to transport data to this server,
    as a replica for a shard, is counted here.

- name: arangodb_replication_dump_documents_total
  renamedFrom: arangodb_replication_dump_documents
  introducedIn: "3.8.0"
  help: |
    Total number of documents replicated in initial asynchronous phase.
  unit: number
  type: counter
  category: Replication
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    During initial replication the existing data from the leader is copied asynchronously
    over to new shards. The amount of documents transported to this server, as a replica for
    a shard, is counted here.

- name: arangodb_replication_dump_request_time_total
  renamedFrom: arangodb_replication_dump_request_time
  introducedIn: "3.8.0"
  help: |
    Accumulated wait time for replication requests in initial asynchronous phase.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    During initial replication the existing data from the leader is copied asynchronously
    over to new shards. The accumulated time the follower waited for the leader to send
    the data is counted here.

- name: arangodb_replication_dump_requests_total
  renamedFrom: arangodb_replication_dump_requests
  introducedIn: "3.8.0"
  help: |
    Number of requests used in initial asynchronous replication phase.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    During initial replication the existing data from the leader is copied asynchronously
    over to new shards. The amount of data transported to this server, as a replica for
    a shard, is counted here.

- name: arangodb_replication_failed_connects_total
  renamedFrom: arangodb_replication_failed_connects
  introducedIn: "3.8.0"
  help: |
    Number of failed connection attempts and response errors during initial
    asynchronous replication.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    During initial replication the existing data from the leader is copied asynchronously
    over to new shards. Whenever there is a communication issue between the follower and
    the leader of the shard it will be counted here for the follower. This communication
    issues cover failed connections or http errors, but they also cover invalid or
    unexpected data formats received on the follower.
  threshold: |
    In ideal situation this counter should be 0. It is expected to increase if there is
    server or network outage. However it is not guaranteed that this metric increases
    in such a situation.
  troubleshoot: |
    If this counter increases this typically indicates an issue with the communication
    between servers. If it is just occasionally an increase of one, it can be a simple
    network hiccup, if you see constant increases here that indicates serious issues.
    This also indicates that there is a shard trying to get into sync with the existing
    data, which cannot make progress. So you have only replicationFactor - 1 copies of
    the data right now. If more servers suffer outage you may lose data in this case.
    * First thing to check: Network connectivity, make sure all servers are online
      and the machines can communicate to one-another.
    * Second: Check ArangoDB logs of this server for more details, most likely
      you will see WARN or ERROR messages in "replication" log topic. If you contact
      ArangoDB support for this issue, it will help to include this servers logs as well.
    * Third: (Unlikely) If the logs contain unexpected format or value entries
      please check if you are running all ArangoDB Database servers within the same
      version of ArangoDB. Only upgrades of one minor version at a time are supported
      in general, so if you are running one server with a much newer / older version
      please upgrade all servers to the newest version.
    * Forth: If none of the above applies, please contact ArangoDB Support.

- name: arangodb_replication_initial_chunks_requests_time_total
  renamedFrom: arangodb_replication_initial_chunks_requests_time
  introducedIn: "3.8.0"
  help: |
    Accumulated wait time for replication key chunks determination requests.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated wait time for replication key
    chunks determination requests, in milliseconds. This is part of the
    older (pre 3.8) initial replication protocol, which might still be used
    in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the time used for the initial step of getting
    the checksums for the key chunks.

- name: arangodb_replication_initial_docs_requests_time_total
  renamedFrom: arangodb_replication_initial_docs_requests_time
  introducedIn: "3.8.0"
  help: |
    Accumulated time needed to request replication docs data.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated wait time for requesting actual
    documents for the initial replication, in milliseconds. This is part
    of the older (pre 3.8) initial replication protocol, which might
    still be used in 3.8 for collections which have been created by older
    versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the time used for the final step of actually
    getting the needed documents.

- name: arangodb_replication_initial_insert_apply_time_total
  renamedFrom: arangodb_replication_initial_insert_apply_time
  introducedIn: "3.8.0"
  help: |
    Accumulated time needed to apply replication initial sync insertions.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    Accumulated time needed to apply replication initial sync insertions.
    This counter exhibits the accumulated wait time for actually inserting
    documents for the initial synchronization, in milliseconds. This is
    part of the older (pre 3.8) initial replication protocol, which might
    still be used in 3.8 for collections which have been created by older
    versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the time used for the actual insertion of
    replicated documents on the follower.

- name: arangodb_replication_initial_keys_requests_time_total
  renamedFrom: arangodb_replication_initial_keys_requests_time
  introducedIn: "3.8.0"
  help: |
    Accumulated wait time for replication keys requests.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated wait time for fetching key
    lists for a chunk, in milliseconds. This is part of the
    older (pre 3.8) initial replication protocol, which might still be used
    in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the time used for the second step of getting
    lists of key/revision pairs for each chunk.

- name: arangodb_replication_initial_remove_apply_time_total
  renamedFrom: arangodb_replication_initial_remove_apply_time
  introducedIn: "3.8.0"
  help: |
    Accumulated time needed to apply replication initial sync removals.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated wait time for removing local
    documents during initial synchronization of a shard on the follower,
    in milliseconds. This is part of the older (pre 3.8) initial
    replication protocol, which might still be used in 3.8 for collections
    which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the time used for the intermediate step of
    removing unneeded documents on the follower.

- name: arangodb_replication_initial_sync_bytes_received_total
  renamedFrom: arangodb_replication_initial_sync_bytes_received
  introducedIn: "3.8.0"
  help: |
    Accumulated amount of bytes received in initial sync.
  unit: bytes
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated number of bytes received
    for initial synchronization of shards. This is part of the
    older (pre 3.8) initial replication protocol, which might still be used
    in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates number of bytes received for all three steps.

- name: arangodb_replication_initial_sync_docs_inserted_total
  renamedFrom: arangodb_replication_initial_sync_docs_inserted
  introducedIn: "3.8.0"
  help: |
    Number of documents inserted by replication initial sync.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the total number of documents inserted on the
    follower during initial synchronization of shards. This is part of the
    older (pre 3.8) initial replication protocol, which might still be
    used in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the total number of documents inserted in the
    third step.

- name: arangodb_replication_initial_sync_docs_removed_total
  renamedFrom: arangodb_replication_initial_sync_docs_removed
  introducedIn: "3.8.0"
  help: |
    Number of documents removed by replication initial sync.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the total number of documents removed on the
    follower during initial synchronization of shards. This is part of the
    older (pre 3.8) initial replication protocol, which might still be
    used in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the total number of documents removed in the
    third step.

- name: arangodb_replication_initial_sync_docs_requested_total
  renamedFrom: arangodb_replication_initial_sync_docs_requested
  introducedIn: "3.8.0"
  help: |
    Number of documents requested by replication initial sync.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the total number of documents fetched on the
    follower from the leader during initial synchronization of shards.
    This is part of the older (pre 3.8) initial replication protocol,
    which might still be used in 3.8 for collections which have been
    created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the total number of documents fetched from the
    leader in the third step.

- name: arangodb_replication_initial_sync_docs_requests_total
  renamedFrom: arangodb_replication_initial_sync_docs_requests
  introducedIn: "3.8.0"
  help: |
    Number of replication initial sync docs requests.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the total number of times documents have been
    fetched on the follower from the leader during initial synchronization
    of shards. This is part of the older (pre 3.8) initial replication
    protocol, which might still be used in 3.8 for collections which have
    been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric accumulates the total number of times documents have been
    fetched from the leader in the third step.

- name: arangodb_replication_initial_sync_keys_requests_total
  renamedFrom: arangodb_replication_initial_sync_keys_requests
  introducedIn: "3.8.0"
  help: |
    Number of replication initial sync keys requests.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    This counter exhibits the accumulated number of keys requests for
    initial synchronization of shards. This is part of the
    older (pre 3.8) initial replication protocol, which might still be used
    in 3.8 for collections which have been created by older versions.
  
    In this older protocol, the follower first fetches an overview over
    a shard from the leader. This does a full collection scan and
    divides the primary keys in the collection into equal sized chunks.
    Then, a checksum for each chunk is returned. The same is then done
    on the follower and the checksums are compared, chunk by chunk. For
    each chunk, for which the checksums do not match, the list of keys and
    revisions is fetched from the leader. This then enables the follower
    to fetch the actually needed documents and remove superfluous ones
    locally.
  
    This metric counts the number of times the follower fetches a list of
    keys for some chunk.

- name: arangodb_replication_synchronous_requests_total_number_total
  renamedFrom: arangodb_replication_synchronous_requests_total_number
  introducedIn: "3.8.0"
  help: |
    Total number of synchronous replication requests.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The total amount of all synchronous replication operation requests
    between DB-Servers being done.

- name: arangodb_replication_synchronous_requests_total_time_total
  renamedFrom: arangodb_replication_synchronous_requests_total_time
  introducedIn: "3.8.0"
  help: |
    Total time needed for all synchronous replication requests.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The total time needed for all synchronous replication requests
    between DB-Servers being done.

- name: arangodb_replication_tailing_apply_time_total
  renamedFrom: arangodb_replication_tailing_apply_time
  introducedIn: "3.8.0"
  help: |
    Accumulated time needed to apply replication tailing data.
  unit: ms
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The accumulated time needed to locally process the continuous
    replication log on a follower received from a replication
    leader.
  troubleshoot: |
    If you see unusual spikes here, the follower might not have enough
    IO bandwidth or might be overloaded. Try to provision more IOPS or
    more CPU capacity. Additionally, it could make sense to compare the
    value with all other available follower DB-Servers to detect potential
    differences.

- name: arangodb_replication_tailing_bytes_received_total
  renamedFrom: arangodb_replication_tailing_bytes_received
  introducedIn: "3.8.0"
  help: |
    Accumulated number of bytes received for replication tailing requests.
  unit: bytes
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description:
    The accumulated number of bytes received from a leader for replication
    tailing requests. The higher the amount of bytes is, the more data
    is being processed afterwards on the follower DB-Server.
  troubleshoot:
    Compare this metric with all other related participating follower
    DB-Servers. If the given value on a DB-Server is considerable higher,
    you might want to think about rebalancing your data as the overall
    work might not be evenly distributed.

- name: arangodb_replication_tailing_documents_total
  renamedFrom: arangodb_replication_tailing_documents
  introducedIn: "3.8.0"
  help: |
    Accumulated number of replication tailing document inserts/replaces processed.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description:
    The accumulated number of replication tailing document inserts/replaces
    processed on a follower.
  troubleshoot:
    Compare this metric with all other related participating follower
    DB-Servers. If the given value on a DB-Server is considerable higher,
    you might want to think about rebalancing your data as the overall
    work might not be evenly distributed. It is important to understand
    that this metric only enumerates the amount of documents and does not
    compare document sizes. Even if values compared to other DB-Servers
    may vary, work load could be fine. Therefore also check the metric
    arangodb_replication_tailing_bytes_received_total to have an overall
    and more precise picture.

- name: arangodb_replication_tailing_follow_tick_failures_total
  renamedFrom: arangodb_replication_tailing_follow_tick_failures
  introducedIn: "3.8.0"
  help: |
    Number of replication tailing failures due to missing tick on leader.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    The number of replication tailing failures due to missing tick on leader.
  troubleshoot:
    If this is non-zero, action is required. A required follower tick is not present (potentially
    removed) on a leader DB-Server. Please check the related leader DB-Server
    log-files to identify the origin of the cause. It may be required to do
    a full re-sync and/or increase the number of historic logfiles on the
    leader(s).

- name: arangodb_replication_tailing_markers_total
  renamedFrom: arangodb_replication_tailing_markers
  introducedIn: "3.8.0"
  help: |
    Number of replication tailing markers processed.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The number of replication tailing markers processed on a follower
    DB-Server. Markers are specific operations which are part of the
    write-ahead log (WAL). Example actions which are being used in
    markers: Create or drop a database. Create, drop, rename, change
    or truncate a collection. Create or drop an index. Create, drop,
    change a view. Start, commit or abort a transaction.

- name: arangodb_replication_tailing_removals_total
  renamedFrom: arangodb_replication_tailing_removals
  introducedIn: "3.8.0"
  help: |
    Number of replication tailing document removals processed.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The amount of document removal based marker operations on a
    follower DB-Server.

- name: arangodb_replication_tailing_request_time_total
  renamedFrom: arangodb_replication_tailing_request_time
  introducedIn: "3.8.0"
  help: |
    Aggregated wait time for replication tailing requests.
  unit: ms
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
  description: |
    Aggregated wait time for replication tailing requests.
  troubleshoot:
    If you see unusual spikes here, please inspect potential
    network issues. It may help to increase network bandwidth
    and/or reduce network latency. In case there are no network
    issues, also check the load of the serving leader DB-Server,
    as well as the follower DB-Server, as they could potentially
    be overloaded and reaching hardware-based limits.

- name: arangodb_replication_tailing_requests_total
  renamedFrom: arangodb_replication_tailing_requests
  introducedIn: "3.8.0"
  help: |
    Number of replication tailing requests.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    The total amount of network replication tailing requests.

- name: arangodb_request_body_size_http1
  introducedIn: "3.7.15"
  help: |
    Body size in bytes for HTTP/1.1 requests.
  unit: bytes
  type: histogram
  category: Statistics
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the body sizes of the received HTTP/1.1 requests in bytes.
    Note that this does not account for the header.

- name: arangodb_request_body_size_http2
  introducedIn: "3.7.15"
  help: |
    Body size in bytes for HTTP/2 requests.
  unit: bytes
  type: histogram
  category: Statistics
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the body sizes of the received HTTP/2 requests in bytes.
    Note that this does not account for the header.

- name: arangodb_request_body_size_vst
  introducedIn: "3.7.15"
  help: |
    Body size in bytes for VST requests.
  unit: bytes
  type: histogram
  category: Statistics
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Histogram of the body sizes of the received VST requests in bytes.
    Note that this does include the binary header.

- name: arangodb_revision_tree_hibernations_total
  introducedIn: "3.8.5"
  help: |
    Number of revision tree hibernations.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    The revision trees of collections/shards are normally present
    in RAM in an uncompressed state. However, to reduce the memory
    usage of keeping all revision trees in RAM at the same time, 
    revision trees can be put into "hibernation" mode. Any inactive
    revision tree will automatically be hibernated by ArangoDB after
    a while. For the hibernation step, a revision tree will be 
    compressed in RAM, and only the compressed version is then kept.
    Later accesses of a compressed revision tree require uncompressing
    the tree again. 
    This metric is increased whenever a revision tree is hibernated.
    This can happened many times during the lifetime of a revision tree.

- name: arangodb_revision_tree_memory_usage
  introducedIn: "3.8.5"
  help: |
    Total memory usage of all revision trees (both hibernated and uncompressed).
  unit: bytes
  type: gauge
  category: Replication
  complexity: simple
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Total memory usage of all revision trees for collections/shards.
    The revision trees of collections/shards are normally present
    in RAM in an uncompressed state. However, to reduce the memory
    usage of keeping all revision trees in RAM at the same time, 
    revision trees can be put into "hibernation" mode. Any inactive
    revision tree will automatically be hibernated by ArangoDB after
    a while. For the hibernation step, a revision tree will be 
    compressed in RAM, and only the compressed version is then kept.
    Later accesses of a compressed revision tree require uncompressing
    the tree again. 
    This metrics reports the total memory usage of all revision trees,
    including both the hibernated and uncompressed forms).

- name: arangodb_revision_tree_rebuilds_failure_total
  introducedIn: "3.8.2"
  help: |
    Number of failed revision tree rebuilds.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Number of failed background revision tree rebuilds.
    Ideally this value stays at 0, because if a revision tree rebuild
    fails, the system may stall and not be able to make progress in
    terms of WAL file collection. In case the counter is increased,
    an error message will also be logged to the arangod logfile.

- name: arangodb_revision_tree_rebuilds_success_total
  introducedIn: "3.8.2"
  help: |
    Number of successful revision tree rebuilds.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    Number of successful background revision tree rebuilds.
    Ideally this value stays at 0, because a revision tree rebuild
    indicates a problem with a collection/shard's revision tree that
    has happened before.

- name: arangodb_revision_tree_resurrections_total
  introducedIn: "3.8.5"
  help: |
    Number of revision tree resurrections.
  unit: number
  type: counter
  category: Replication
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    The revision trees of collections/shards are normally present
    in RAM in an uncompressed state. However, to reduce the memory
    usage of keeping all revision trees in RAM at the same time, 
    revision trees can be put into "hibernation" mode. Any inactive
    revision tree will automatically be hibernated by ArangoDB after
    a while. For the hibernation step, a revision tree will be 
    compressed in RAM, and only the compressed version is then kept.
    Later accesses of a compressed revision tree require uncompressing
    the tree again. 
    This metric is increased whenever a revision tree is restored from
    its hibernated state back into an uncompressed form in RAM.
    This can happened many times during the lifetime of a revision tree.

- name: arangodb_rocksdb_write_stalls_total
  renamedFrom: rocksdb_write_stalls
  introducedIn: "3.8.0"
  help: |
    Number of times RocksDB has entered a stalled (slowed) write state.
  unit: number
  type: counter
  category: RocksDB
  complexity: simple
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the number of times RocksDB was observed by
    ArangoDB to have entered a stalled (slowed) write state.
    
    If the RocksDB background threads which do cleanup and compaction
    cannot keep up with the writing, then RocksDB first throttles its
    write rate ("write stall") and later stops the writing entirely
    ("write stop"). Both are suboptimal, since the write rate is too high.
  threshold: |
    If this number grows, you are probably writing faster to ArangoDB than
    RocksDB can keep up with its background processing. This is OK for
    a while, but might eventually lead to actual write stops, which are
    bad since they can lead to unavailability.
  troubleshoot: |
    Quite often, RocksDB is limited by the available I/O bandwidth. Sometimes,
    it is not the bandwidth itself, but the number of I/O operations per
    second (IOPS) which is limited. If you are in a cloud environment,
    IOPS are often scarce (or expensive) and you might be able to
    deploy more.

- name: arangodb_rocksdb_write_stops_total
  renamedFrom: rocksdb_write_stops
  introducedIn: "3.8.0"
  help: |
    Number of times RocksDB has entered a stopped write state.
  unit: number
  type: counter
  category: RocksDB
  complexity: simple
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the number of times RocksDB was observed by
    ArangoDB to have entered a stopped write state.
    
    If the RocksDB background threads which do cleanup and compaction
    cannot keep up with the writing, then RocksDB first throttles its
    write rate ("write stall") and later stops the writing entirely
    ("write stop"). Both are suboptimal, since the write rate is too high,
    but write stops are considerably worse, since they can lead to service
    unavailability.
  threshold: |
    If this number grows, you are probably writing a lot faster to
    ArangoDB than RocksDB can keep up with its background processing.
    This has lead to actual write stops, which are bad since they can lead
    to unavailability. If you see this number grow, you need to act,
    if in doubt, contact ArangoDB support.
  troubleshoot: |
    Quite often, RocksDB is limited by the available I/O bandwidth. Sometimes,
    it is not the bandwidth itself, but the number of I/O operations per
    second (IOPS) which is limited. If you are in a cloud environment,
    IOPS are often scarce (or expensive) and you might be able to
    deploy more.

- name: arangodb_scheduler_handler_tasks_created_total
  introducedIn: "3.8.2"
  help: |
    Total number of REST handler tasks created for the scheduler.
  unit: number
  type: counter
  category: Scheduler
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of REST handler tasks that were created for execution
    via the scheduler. This counter is increased for each incoming
    request for which a REST handler mapping exists and that does not
    need to be forwarded to another coordinator in the cluster.

- name: arangodb_scheduler_high_prio_queue_length
  introducedIn: "3.8.0"
  help: |
    Current queue length of the high priority queue in the scheduler.
  unit: number
  type: gauge
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of jobs currently queued on the scheduler's high priority queue.
    The capacity of the high priority queue can be configured via the startup
    option `--server.prio1-size`.

- name: arangodb_scheduler_jobs_dequeued_total
  introducedIn: "3.8.0"
  help: |
    Total number of jobs dequeued.
  unit: number
  type: counter
  category: Scheduler
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The total number of jobs dequeued from all scheduler queues.
    Calculating the difference between arangodb_scheduler_jobs_submitted_total
    and arangodb_scheduler_jobs_dequeued_total gives the total number of
    currently queued jobs.
    Calculating the difference between arangodb_scheduler_jobs_dequeued_total
    and arangodb_scheduler_jobs_done_total gives the number of jobs currently
    being processed.

- name: arangodb_scheduler_jobs_done_total
  introducedIn: "3.8.0"
  help: |
    Total number of queue jobs done.
  unit: number
  type: gauge
  category: Scheduler
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The total number of queue jobs done.
    Calculating the difference between arangodb_scheduler_jobs_dequeued_total
    and arangodb_scheduler_jobs_done_total gives the total number of jobs
    currently being processed.

- name: arangodb_scheduler_jobs_submitted_total
  introducedIn: "3.8.0"
  help: |
    Total number of jobs submitted to the scheduler.
  unit: number
  type: gauge
  category: Scheduler
  complexity: advanced
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of jobs submitted to the scheduler.
    Calculating the difference between arangodb_scheduler_jobs_submitted_total
    and arangodb_scheduler_jobs_dequeued_total gives the total number of
    currently queued jobs.

- name: arangodb_scheduler_low_prio_queue_last_dequeue_time
  introducedIn: "3.8.0"
  help: |
    Last recorded dequeue time for a low priority queue item.
  unit: ms
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Last recorded dequeue time for a low priority queue item, i.e., the amount of
    time the job was sitting in the queue. If there is nothing to do for a long
    time, this metric will be reset to zero.
    A large value for this metric indicates that the server is under heavy load
    and low priority jobs cannot be dequeued in a timely manner
  threshold: Normally this time should be clearly sub-second.
  troubleshoot: If you see larger values here, in particular over a longer period
    of time, you should consider reducing the load of the server (if possible),
    scaling up (bigger machine) or scaling out (more Coordinators). Otherwise
    requests cannot be processed in a timely manner and you run the risk that the
    queue becomes full and requests are declined.

- name: arangodb_scheduler_low_prio_queue_length
  introducedIn: "3.8.0"
  help: |
    Current queue length of the low priority queue in the scheduler.
  unit: number
  type: gauge
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of jobs currently queued on the scheduler's low priority queue.
    The capacity of the low priority queue can be configured via the startup
    option `--server.maximal-queue-size`.

- name: arangodb_scheduler_maintenance_prio_queue_length
  introducedIn: "3.8.0"
  help: |
    Current queue length of the maintenance priority queue in the scheduler.
  unit: number
  type: gauge
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of jobs currently queued on the scheduler's maintenance priority
    queue. These are the jobs with the highest priority and are mainly used for
    cluster internal operations. The capacity of the maintenance priority queue
    can be configured via the startup option `--server.scheduler-queue-size`.

- name: arangodb_scheduler_medium_prio_queue_length
  introducedIn: "3.8.0"
  help: |
    Current queue length of the medium priority queue in the scheduler.
  unit: number
  type: gauge
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of jobs currently queued on the scheduler's medium priority queue.
    The capacity of the medium priority queue can be configured via the startup
    option `--server.prio2-size`.

- name: arangodb_scheduler_num_awake_threads
  renamedFrom: arangodb_scheduler_awake_threads
  introducedIn: "3.8.0"
  help: |
    Number of awake worker threads.
  unit: number
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of worker threads currently working on some job or spinning while
    waiting for new work (i.e., not sleeping).

- name: arangodb_scheduler_num_worker_threads
  introducedIn: "3.6.7"
  help: |
    Current number of worker threads.
  unit: number
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The number of worker threads currently started. Worker threads can be started
    and stopped dynamically based on the server load.

- name: arangodb_scheduler_num_working_threads
  introducedIn: "3.6.10"
  help: |
    Current number of working threads.
  unit: number
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The current number of threads actually working on some job (i.e., not
    spinning while waiting for new work).

- name: arangodb_scheduler_ongoing_low_prio
  introducedIn: "3.8.0"
  help: |
    Total number of ongoing RestHandlers coming from the low priority queue.
  unit: number
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of low priority jobs currently being processed.

- name: arangodb_scheduler_queue_full_failures_total
  renamedFrom: arangodb_scheduler_queue_full_failures
  introducedIn: "3.8.0"
  help: |
    Number of tasks dropped and not added to internal queue.
  unit: number
  type: counter
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of tasks dropped because the queue was already full. The queue capacities
    can be configured via the startup options `--server.scheduler-queue-size`,
    `--server.prio1-size`, `--server.prio2-size` and `--server.maximal-queue-size`.

- name: arangodb_scheduler_queue_length
  introducedIn: "3.6.7"
  help: |
    Server's internal queue length.
  unit: number
  type: gauge
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    The total number of currently queued jobs in all queues.

- name: arangodb_scheduler_queue_time_violations_total
  introducedIn: "3.9.0"
  help: |
    Number of tasks/requests dropped and not added to internal queue
    due to the client-specified queue time requirements not being
    satisfiable.
  unit: number
  type: counter
  category: Scheduler
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of tasks/requests dropped because the client-specified queue time
    requirements, as indicated by client applications in the request header
    "x-arango-queue-time-seconds" could not be satisfied by the receiving 
    server instance. This happens when the actual time need to queue/dequeue
    requests on the scheduler queue exceeds the maximum time value that the
    client has specified in the request. 
    Whenever this happens, the client application will get an HTTP 412 error 
    response back with error code 21004 ("queue time violated").
    Although the metric is exposed on all instance types, it will very likely
    always be 0 on DB servers, simply because coordinators do not forward the
    "x-arango-queue-time-seconds" when they send internal requests to DB
    servers.

- name: arangodb_scheduler_threads_started_total
  renamedFrom: arangodb_scheduler_threads_started
  introducedIn: "3.8.0"
  help: |
    Total accumulated number of scheduler threads started.
  unit: number
  type: counter
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total accumulated number of scheduler threads started. Worker threads can be
    started and stopped dynamically based on the server load.

- name: arangodb_scheduler_threads_stopped_total
  renamedFrom: arangodb_scheduler_threads_stopped
  introducedIn: "3.8.0"
  help: |
    Accumulated total number of scheduler threads stopped.
  unit: number
  type: counter
  category: Scheduler
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total accumulated number of scheduler threads stopped. Worker threads can be
    started and stopped dynamically based on the server load.

- name: arangodb_search_cleanup_time
  introducedIn: "3.10.0"
  help: |
    Average time of few last cleanups.
  unit: ms
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Average time of few last cleanups.

- name: arangodb_search_commit_time
  introducedIn: "3.10.0"
  help: |
    Average time of few last commits.
  unit: ms
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Average time of few last commits.

- name: arangodb_search_consolidation_time
  introducedIn: "3.10.0"
  help: |
    Average time of few last consolidations.
  unit: ms
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Average time of few last consolidations.

- name: arangodb_search_index_size
  introducedIn: "3.10.0"
  help: |
    Size of the index in bytes for current snapshot.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Size of the index in bytes for current snapshot.

- name: arangodb_search_num_docs
  introducedIn: "3.10.0"
  help: |
    Number of documents for current snapshot.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of documents for current snapshot.

- name: arangodb_search_num_failed_cleanups
  introducedIn: "3.10.0"
  help: |
    Number of failed cleanups.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of failed cleanups.

- name: arangodb_search_num_failed_commits
  introducedIn: "3.10.0"
  help: |
    Number of failed commits.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of failed commits.

- name: arangodb_search_num_failed_consolidations
  introducedIn: "3.10.0"
  help: |
    Number of failed consolidations.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of failed consolidations.

- name: arangodb_search_num_files
  introducedIn: "3.10.0"
  help: |
    Number of files for current snapshot.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of files for current snapshot.

- name: arangodb_search_num_live_docs
  introducedIn: "3.10.0"
  help: |
    Number of live documents for current snapshot.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of live documents for current snapshot.

- name: arangodb_search_num_segments
  introducedIn: "3.10.0"
  help: |
    Number of segments for current snapshot.
  unit: number
  type: gauge
  category: ArangoSearch
  complexity: advanced
  exposedBy:
    - dbserver
    - single
  description: |
    Number of segments for current snapshot.

- name: arangodb_server_statistics_cpu_cores
  introducedIn: "3.8.0"
  help: |
    Number of CPU cores visible to the arangod process.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of CPU cores visible to the arangod process, unless the
    environment variable `ARANGODB_OVERRIDE_DETECTED_NUMBER_OF_CORES`
    is set. In that case, the environment variable's value will be reported.

- name: arangodb_server_statistics_idle_percent
  introducedIn: "3.8.0"
  help: |
    Percentage of time that the system CPUs have been idle.
  unit: percentage
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Percentage of time that the system CPUs have been idle, as
    a value between 0 and 100, and as reported by the operating system.
    This metric is only reported on some operating systems.

- name: arangodb_server_statistics_iowait_percent
  introducedIn: "3.8.0"
  help: |
    Percentage of time that the system CPUs have been waiting for I/O.
  unit: percentage
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Percentage of time that the system CPUs have been waiting for I/O, as
    a value between 0 and 100, and as reported by the operating system.
    This metric is only reported on some operating systems.

- name: arangodb_server_statistics_physical_memory
  introducedIn: "3.6.7"
  help: |
    Physical memory in bytes.
  unit: bytes
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Physical memory of the system in bytes, as reported by the operating system
    unless the environment variable `ARANGODB_OVERRIDE_DETECTED_TOTAL_MEMORY`
    is set. In that case, the environment variable's value will be reported.

- name: arangodb_server_statistics_server_uptime_total
  renamedFrom: arangodb_server_statistics_server_uptime
  introducedIn: "3.8.0"
  help: |
    Number of seconds elapsed since server start.
  unit: s
  type: counter
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of seconds elapsed since server start, including fractional
    seconds.
    This metric was named `arangodb_server_statistics_server_uptime`
    in previous versions of ArangoDB.

- name: arangodb_server_statistics_system_percent
  introducedIn: "3.8.0"
  help: |
    Percentage of time that the system CPUs have spent in kernel mode.
  unit: percentage
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Percentage of time that the system CPUs have spent in kernel mode, as
    a value between 0 and 100, and as reported by the operating system.
    This metric is only reported on some operating systems.

- name: arangodb_server_statistics_user_percent
  introducedIn: "3.8.0"
  help: |
    Percentage of time that the system CPUs have spent in user mode.
  unit: percentage
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Percentage of time that the system CPUs have spent in user mode, as
    a value between 0 and 100, and as reported by the operating system.
    This metric is only reported on some operating systems.

- name: arangodb_shards_leader_number
  renamedFrom: arangodb_shards_leader_count
  introducedIn: "3.8.0"
  help: |
    Number of leader shards on this machine.
  unit: number
  type: gauge
  category: Replication
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Number of leader shards on this machine. Every shard has a leader and
    potentially multiple followers.
  troubleshoot: |
    Since the leaders perform all the read and write operations and
    the followers only replicate the writes, one should usually have a
    relatively even distribution of leader shards across DB-Servers. An
    exception can be one-shard deployments, in which every collection has
    a single shard and all shards in a database must have the same leader.
    If you have few databases in a one-shard deployment, then an uneven
    distribution of leader shards is natural.
    
    You can either move shards manually, use the "Rebalance shards" button
    in the UI, or use the
    [cluster maintenance tools](https://github.com/arangodb/cluster-maintenance)
    (`create-move-plan` and `execute-move-plan` specifically). In the latter
    case, contact ArangoDB customer support.

- name: arangodb_shards_not_replicated
  introducedIn: "3.7.1"
  help: |
    Number of shards not replicated at all.
  unit: number
  type: gauge
  category: Replication
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Number of shards not replicated at all. This is counted for all shards
    for which this server is currently the leader. The number is increased
    by one for every shards for which no follower is in sync.
  troubleshoot: |
    Needless to say, such a situation is very bad for resilience, since it
    indicates a single point of failure. So, if this number is larger than 0,
    then some action is indicated. During an upgrade or when some DB-Server
    was restarted, it can happen that shard followers are out of sync.
    Normally, shards should get in sync on their own, so observation
    and waiting is a good measure at first. However, if the situation
    persists, something is wrong, potentially some constant server crash
    (maybe out of memory crashes?) or another situation preventing
    shards to get in sync. Contact ArangoDB customer support in this case.

- name: arangodb_shards_number
  renamedFrom: arangodb_shards_total_count
  introducedIn: "3.8.0"
  help: |
    Number of shards on this machine.
  unit: number
  type: gauge
  category: Replication
  complexity: simple
  exposedBy:
    - dbserver
  description: |
    Number of shards on this machine. Every shard has a leader and
    potentially multiple followers. This metric counts both leader and
    follower shards.
  troubleshoot: |
    Since both leader and follower shards use memory and disk space,
    the total number of shards should be approximately balanced
    evenly across the DB-Servers. To achieve this, you can either
    move shards manually, use the "Rebalance shards" button in the
    UI, or use the
    [cluster maintenance tools](https://github.com/arangodb/cluster-maintenance)
    (`create-move-plan` and `execute-move-plan` specifically). In the latter
    case, contact ArangoDB customer support.

- name: arangodb_shards_out_of_sync
  introducedIn: "3.7.1"
  help: |
    Number of leader shards not fully replicated.
  unit: number
  type: gauge
  category: Replication
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
  description: |
    Number of leader shards not fully replicated. This is counted for all
    shards for which this server is currently the leader. The number is
    increased by one for every shards for which not all followers are in sync.
  troubleshoot: |
    Needless to say, such a situation is not good resilience, since we
    do not have as many copies of the data as the `replicationFactor`
    prescribes. If this metrics has a value larger than 0, then some
    action is indicated. During an upgrade or when some DB-Server was
    restarted, it can happen that shard followers are out of sync.
    Normally, shards should get in sync on their own, so observation
    and waiting is a good measure at first. However, if the situation
    persists, something is wrong, potentially some constant server crash
    (maybe out of memory crashes?) or another situation preventing shards
    to get in sync. Contact ArangoDB customer support in this case.

- name: arangodb_sync_rebuilds_total
  introducedIn: "3.8.0"
  help: |
    Number of times a follower shard needed to be completely rebuilt because of
    too many synchronization failures.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
    - single
  description: |
    Number of times a follower shard needed to be completely rebuilt
    because of too many subsequent shard synchronization failures.
    If this metric is non-zero, it means that a follower shard could
    not get in sync with the leader even after many attempts. When
    the metric gets increased, the follower shard is dropped and
    completely rebuilt from leader data, in order to increase its
    chances of getting in sync.
  troubleshoot: |
    Normally, this number will always be 0. If it is not, then something
    is wrong, please contact ArangoDB customer support in this case.

- name: arangodb_sync_timeouts_total
  introducedIn: "3.9.2"
  help: |
    Number of times the synchronization of a follower shard synchronization
    attempt ran into a timeout.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
  description: |
    Number of times a follower shard synchronization attempt ran into the
    timeout controlled by the startup option `--cluster.shard-synchronization-attempt-timeout`.
    Running into this timeout is not an error. The timeout simply restricts
    individual shard synchronization attempts to a certain maximum runtime.
    When it happens, the shard synchronization attempt is aborted by the
    follower, but immediately retried afterwards. This abort-and-retry
    operation allows the leader DB servers to purge their archived WAL files
    for the aborted snapshots timely, so that long-running shard synchronization
    aborts do not lead to overly long WAL file retention periods on leaders.

- name: arangodb_sync_wrong_checksum_total
  renamedFrom: arangodb_sync_wrong_checksum
  introducedIn: "3.8.0"
  help: |
    Number of times a mismatching shard checksum was detected when syncing shards.
  unit: number
  type: counter
  category: Replication
  complexity: medium
  exposedBy:
    - dbserver
    - single
  description: |
    Number of times a mismatching shard checksum was detected when
    syncing shards. This is a very special metric which is rarely used.
    When followers of shards get in sync with their leaders, just when
    everything is completed a final checksum is taken as an additional
    precaution. If this checksum differs between leader an follower, the
    incremental resync process starts from scratch.
  troubleshoot: |
    Normally, this number will always be 0. If it is not, then usually
    something is wrong, please contact ArangoDB customer support in this
    case.

- name: arangodb_transactions_aborted_total
  renamedFrom: arangodb_transactions_aborted
  introducedIn: "3.8.0"
  help: |
    Number of transactions aborted.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of transactions aborted. In the cluster, this metric will
    be collected separately for transactions on Coordinators and the
    transaction counterparts on leaders and followers.
    This metric was named `arangodb_transactions_aborted` in previous
    versions of ArangoDB.

- name: arangodb_transactions_committed_total
  renamedFrom: arangodb_transactions_committed
  introducedIn: "3.8.0"
  help: |
    Number of transactions committed.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of transactions committed. In the cluster, this metric will
    be collected separately for transactions on Coordinators and the
    transaction counterparts on leaders and followers.
    This metric was named `arangodb_transactions_committed` in previous
    versions of ArangoDB.

- name: arangodb_transactions_expired_total
  renamedFrom: arangodb_transactions_expired
  introducedIn: "3.8.0"
  help: |
    Total number of expired transactions.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of expired transactions, i.e. transactions that have
    been begun but that were automatically garbage-collected due to
    inactivity within the transactions' time-to-live (TTL) period.
    In the cluster, this metric will be collected separately for transactions
    on Coordinators and the transaction counterparts on leaders and followers.
    This metric was named `arangodb_transactions_expired` in previous
    versions of ArangoDB.

- name: arangodb_transactions_started_total
  renamedFrom: arangodb_transactions_started
  introducedIn: "3.8.0"
  help: |
    Number of transactions started.
  unit: number
  type: counter
  category: Transactions
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of transactions started/begun. In the cluster, this metric will
    be collected separately for transactions on Coordinators and the
    transaction counterparts on leaders and followers.
    This metric was named `arangodb_transactions_started` in previous
    versions of ArangoDB.

- name: arangodb_v8_context_alive
  introducedIn: "3.6.7"
  help: |
    Number of V8 contexts currently alive.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of V8 contexts currently alive. Normally, only Coordinators and
    single servers should have V8 contexts, for DB-Servers and Agents the
    value is always zero.
  threshold: |
    If this number is close to the maximum allowed number of V8 contexts,
    there might be a shortage. This can delay Foxx queries and AQL
    user defined functions. On the other hand, V8 contexts can use
    quite a lot of memory, so one should not have too many if RAM
    is scarce.

- name: arangodb_v8_context_busy
  introducedIn: "3.6.7"
  help: |
    Number of V8 contexts currently busy.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Number of V8 contexts currently busy, that means, they are currently
    working on some JavaScript task. Normally, only Coordinators and
    single servers should have V8 contexts, for DB-Servers and Agents the
    value is always zero.
  threshold: |
    If this number is close to the maximum allowed number of V8 contexts,
    there might be a shortage. This can delay Foxx queries and AQL
    user defined functions. On the other hand, V8 contexts can use
    quite a lot of memory, so one should not have too many if RAM
    is scarce.

- name: arangodb_v8_context_created_total
  renamedFrom: arangodb_v8_context_created
  introducedIn: "3.8.0"
  help: |
    Total number of V8 contexts ever created.
  unit: number
  type: counter
  category: V8
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of V8 contexts ever created. It is
    OK if this number keeps growing since the V8 contexts are created and
    destroyed as needed. In rare cases a high fluctuation can indicate
    some unfortunate usage pattern.

- name: arangodb_v8_context_creation_time_msec_total
  renamedFrom: arangodb_v8_context_creation_time_msec
  introducedIn: "3.8.0"
  help: |
    Accumulated total time for creating V8 contexts.
  unit: ms
  type: counter
  category: V8
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the accumulated total time for creating V8
    contexts, in milliseconds. It is OK if this number keeps growing since
    the V8 contexts are created and destroyed as needed. In rare cases a
    high fluctuation can indicate some unfortunate usage pattern.

- name: arangodb_v8_context_destroyed_total
  renamedFrom: arangodb_v8_context_destroyed
  introducedIn: "3.8.0"
  help: |
    Total number of V8 contexts ever destroyed.
  unit: number
  type: counter
  category: V8
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of V8 contexts ever destroyed.
    It is OK if this number keeps growing since the V8 contexts are
    created and destroyed as needed. In rare cases a high fluctuation can
    indicate some unfortunate usage pattern.

- name: arangodb_v8_context_dirty
  introducedIn: "3.6.7"
  help: |
    Number of V8 contexts currently dirty.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This gauge reflects the number of V8 contexts that are currently dirty.
    A V8 context is dirty, if it has executed JavaScript for some time and
    is due for a garbage collection.

- name: arangodb_v8_context_enter_failures_total
  renamedFrom: arangodb_v8_context_enter_failures
  introducedIn: "3.8.0"
  help: |
    Total number of V8 context enter failures.
  unit: number
  type: counter
  category: V8
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of V8 context enter failures. A context receives a context
    enter event every time it begins to execute some JavaScript. If no
    context is available at such a time the system waits for 60s for a
    context to become free. If this does not happen within the 60s, the
    context enter event fails, a warning is logged and this counter is
    increased by one.
  threshold: |
    If you see V8 context enter failures, then you do not have enough
    V8 contexts or the server is overloaded by JavaScript tasks. If some
    JavaScript code blocks V8 contexts for too long, the free V8 contexts
    can run out and these failures begin to happen.

- name: arangodb_v8_context_entered_total
  renamedFrom: arangodb_v8_context_entered
  introducedIn: "3.8.0"
  help: |
    Total number of V8 context enter events.
  unit: number
  type: counter
  category: V8
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of V8 context enter events. A context receives a context
    enter event every time it begins to execute some JavaScript. This number
    is a rough estimate as to how much JavaScript the server executes.

- name: arangodb_v8_context_exited_total
  renamedFrom: arangodb_v8_context_exited
  introducedIn: "3.8.0"
  help: |
    Total number of V8 context exit events.
  unit: number
  type: counter
  category: V8
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This counter reflects the total number of V8 context exit events.
    A context receives a context exit event every time it finishes to
    execute some JavaScript.

- name: arangodb_v8_context_free
  introducedIn: "3.6.7"
  help: |
    Number of V8 contexts currently free.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This gauge reflects the number of V8 contexts that are currently free.
    If this number drops to 0 there might be a shortage of V8 contexts.

- name: arangodb_v8_context_max
  introducedIn: "3.6.7"
  help: |
    Maximum number of concurrent V8 contexts.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This is the maximum number of concurrent V8 contexts. This is limited
    by a server option, since V8 contexts can use a lot of RAM. V8 contexts
    are created and destroyed as needed up to the limit shown in this metric.

- name: arangodb_v8_context_min
  introducedIn: "3.6.7"
  help: |
    Minimum number of concurrent V8 contexts.
  unit: number
  type: gauge
  category: Statistics
  complexity: simple
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    This is the minimum number of concurrent V8 contexts. This is limited
    by a server option. V8 contexts are created and destroyed as needed
    but there are never fewer than the limit shown in this metric.

- name: arangodb_vst_connections_total
  introducedIn: "3.7.15"
  help: |
    Total number of VST connections accepted.
  unit: number
  type: counter
  category: Connectivity
  complexity: medium
  exposedBy:
    - coordinator
    - dbserver
    - agent
    - single
  description: |
    Total number of connections accepted for VST, this are upgraded
    connections from HTTP/1.1.

- name: rocksdb_actual_delayed_write_rate
  introducedIn: "3.6.1"
  help: |
    Actual delayed RocksDB write rate.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-actual-delayed-write-rate".
    It shows the current actual delayed write rate. The value 0 means no delay.

- name: rocksdb_archived_wal_files
  introducedIn: "3.8.2"
  help: |
    Number of RocksDB WAL files in the archive.
  unit: number
  type: gauge
  category: RocksDB
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the total number of RocksDB WAL files in the
    "archive" subdirectory. These are WAL files that can be garbage-collected
    eventually, when they are not used anymore by replication or other WAL
    tailing.

- name: rocksdb_background_errors
  introducedIn: "3.6.1"
  help: |
    Total number of RocksDB background errors.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "background-errors". It shows
    the accumulated number of background errors.

- name: rocksdb_base_level
  introducedIn: "3.6.1"
  help: |
    RocksDB base level.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-base-level".
    It shows the number of the level to which L0 data will be
    compacted.

- name: rocksdb_block_cache_capacity
  introducedIn: "3.6.1"
  help: |
    RocksDB block cache capacity.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-block-cache-capacity".
    It shows the block cache capacity in bytes. This can be configured with
    the `--rocksdb.block-cache-size` startup option.

- name: rocksdb_block_cache_pinned_usage
  introducedIn: "3.6.1"
  help: |
    Size of pinned RocksDB block cache entries.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-block-cache-pinned-usage".
    It shows the memory size for the RocksDB block cache for the entries
    which are pinned, in bytes.

- name: rocksdb_block_cache_usage
  introducedIn: "3.6.1"
  help: |
    Cumulated size of RocksDB block cache entries.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-block-cache-usage".
    It shows the total memory size for the entries residing in the block cache,
    in bytes.

- name: rocksdb_cache_active_tables
  introducedIn: "3.10.0"
  help: |
    Global current number of hash tables in ArangoDB cache.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the current number of active hash tables used by the
    in-memory cache which sits in front of RocksDB. Active tables are used for
    caching index entries. There should be one active table per index per shard
    for each index that has in-memory caching enabled. There can also be
    additional active tables while an existing hash table is migrated to a
    larger table.

- name: rocksdb_cache_allocated
  introducedIn: "3.6.1"
  help: |
    Global current memory allocation of ArangoDB in-memory caches.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the current global allocation for the ArangoDB
    in-memory cache which sits in front of RocksDB. For example, the edge caches
    counts towards this allocation. All these caches together have a
    global limit which can be controlled with the `--cache.size` startup option.

- name: rocksdb_cache_hit_rate_lifetime
  introducedIn: "3.6.1"
  help: |
    Lifetime hit rate of the ArangoDB cache in front of RocksDB.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the lifetime hit rate of the ArangoDB in-memory
    cache which is sitting in front of RocksDB. For example, the edge
    cache is a part of this. The value will be a ratio between 0 and 1.
    "Lifetime" means here that accounting is done from the most recent
    start of the `arangod` instance.
    If the hit rate is too low, you might have to little RAM available
    for the in-memory caches.

- name: rocksdb_cache_hit_rate_recent
  introducedIn: "3.6.1"
  help: |
    Recent hit rate of the ArangoDB cache in front of RocksDB.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the recent hit rate of the ArangoDB in-memory
    cache which is sitting in front of RocksDB. For example, the edge
    cache is a part of this. The value will be a ratio between 0 and 1.
    If the hit rate is too low, you might have to little RAM available
    for the in-memory caches.

- name: rocksdb_cache_limit
  introducedIn: "3.6.1"
  help: |
    Global allocation limit for the ArangoDB cache in front of RocksDB.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the current global allocation limit for the
    ArangoDB caches which sit in front of RocksDB. For example, the
    edge cache counts towards this allocation. This global limit can
    be controlled with the `--cache.size` startup option.

- name: rocksdb_cache_unused_memory
  introducedIn: "3.10.0"
  help: |
    Global current memory allocation of inactive/reserve hash tables in ArangoDB cache.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the current memory allocation for unused hash tables 
    used by the in-memory cache which sits in front of RocksDB. Unused tables 
    can be kept as backups to provide new, readily initialized tables for new 
    caches. The overall memory usage of unused tables is capped by the system,
    so it will not grow overly large.

- name: rocksdb_cache_unused_tables
  introducedIn: "3.10.0"
  help: |
    Global current number of inactive/reserve hash tables in ArangoDB cache.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reflects the current number of unused hash tables used by the
    in-memory cache which sits in front of RocksDB. Unused tables can be kept as
    backups to provide new, readily initialized tables for new caches.
    Unused tables can consume some memory, but the overall memory usage of
    unused tables is capped.

- name: rocksdb_compaction_pending
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB column families with pending compaction.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "compaction-pending".
    It shows the number of column families for which at least one compaction
    is pending.

- name: rocksdb_compression_ratio_at_level0
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 0.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 0 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 0.

- name: rocksdb_compression_ratio_at_level1
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 1.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 1 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 1.

- name: rocksdb_compression_ratio_at_level2
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 2.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 2 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 2.

- name: rocksdb_compression_ratio_at_level3
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 3.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 3 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 3.

- name: rocksdb_compression_ratio_at_level4
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 4.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 4 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 4.

- name: rocksdb_compression_ratio_at_level5
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 5.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 5 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 5.

- name: rocksdb_compression_ratio_at_level6
  introducedIn: "3.6.1"
  help: |
    RocksDB compression ratio at level 6.
  unit: ratio
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the compression ratio of data at level 6 in RocksDB's
    log structured merge tree. Here, compression
    ratio is defined as uncompressed data size / compressed file size.
    Returns "-1.0" if there are no open files at level 6.

- name: rocksdb_cur_size_active_mem_table
  introducedIn: "3.6.1"
  help: |
    Approximate size of RocksDB's active memtable.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-cur-size-active-mem-table".
    It shows the approximate size of the active memtable in bytes, summed
    over all column families.

- name: rocksdb_cur_size_all_mem_tables
  introducedIn: "3.6.1"
  help: |
    Approximate size of all active and unflushed RocksDB memtables.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-cur-size-all-mem-tables".
    It shows the approximate size of active and unflushed immutable memtables
    in bytes, summed over all column families.

- name: rocksdb_engine_throttle_bps
  renamedFrom: rocksdbengine_throttle_bps
  introducedIn: "3.8.0"
  help: |
    Current rate of the RocksDB throttle in bytes per second.
  unit: bytes per second
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exposes the current write rate limit of the ArangoDB
    RocksDB throttle. The throttle limits the write rate to allow
    RocksDB's background threads to catch up with compactions and not
    fall behind too much, since this would in the end lead to nasty
    write stops in RocksDB and incur considerable delays. If 0 is
    shown, no throttling happens, otherwise, you see the current
    write rate limit in bytes per second. Also see the `--rocksdb.*`
    startup options.

- name: rocksdb_estimate_live_data_size
  introducedIn: "3.6.1"
  help: |
    Estimated amount of live RocksDB data.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-estimate-live-data-size".
    It shows an estimate of the amount of live data in bytes, summed over
    all column families.

- name: rocksdb_estimate_num_keys
  introducedIn: "3.6.1"
  help: |
    Estimated number of RocksDB keys.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-estimate-num-keys".
    It shows the estimated number of total keys in the active and unflushed
    immutable memtables and storage, summed over all column families.

- name: rocksdb_estimate_pending_compaction_bytes
  introducedIn: "3.6.1"
  help: |
    Estimated number of bytes awaiting RocksDB compaction.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-estimate-pending-compaction-bytes".
    It shows the estimated total number of bytes compaction needs to
    rewrite to get all levels down to under target size. Not valid for
    other compactions than level-based. This value is summed over all
    column families.

- name: rocksdb_estimate_table_readers_mem
  introducedIn: "3.6.1"
  help: |
    Estimated memory usage for reading RocksDB SST tables.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-estimate-table-readers-mem".
    It shows the estimated memory used for reading SST tables, excluding
    memory used in block cache (e.g. filter and index blocks), summed over
    all column families.

- name: rocksdb_free_disk_space
  introducedIn: "3.8.0"
  help: |
    Free disk space in bytes on volume used by RocksDB.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric shows the currently free disk space in bytes on the volume
    which is used by RocksDB. Since RocksDB does not like out of disk
    space scenarios, please make sure that there is enough free disk space
    available at all times!  Note that this metric is only available/populated on some platforms.

- name: rocksdb_free_inodes
  introducedIn: "3.8.0"
  help: |
    Number of free inodes on the volume used by RocksDB.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric shows the currently free number of inodes on the disk volume
    used by RocksDB. Since RocksDB does not like out of disk space
    scenarios, please make sure that there is enough free inodes available
    at all times! Note that this metric is only available/populated on some platforms.

- name: rocksdb_is_file_deletions_enabled
  introducedIn: "3.6.1"
  help: |
    Whether RocksDB file deletion is enabled.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-is-file-deletions-enabled".
    It shows 0 if deletion of obsolete files is enabled, and otherwise,
    it shows a non-zero number. Note that for ArangoDB, this is supposed
    to always return 1, since the deletion of obsolete WAL files is done
    from ArangoDB, externally to RocksDB.

- name: rocksdb_is_write_stopped
  introducedIn: "3.6.1"
  help: |
    Whether RocksDB writes are stopped.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-is-write-stopped".
    It shows 1 if writing to RocksDB has been stopped, and otherwise 0.
    If 1 is shown, this usually means that there are too many uncompacted
    files and the RocksDB background threads have not managed to keep up
    with their compaction work. This situation should be avoided, since
    nasty delays in database operations are incurred. If in doubt,
    contact ArangoDB support.

- name: rocksdb_live_sst_files_size
  introducedIn: "3.6.1"
  help: |
    Size of live RocksDB SST files.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-live-sst-files-size".
    It shows the total size in bytes of all SST files belonging to the latest
    LSM tree, summed over all column families.

- name: rocksdb_mem_table_flush_pending
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB column families awaiting memtable flush.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "mem-table-flush-pending". It
    shows the number of column families for which a memtable flush is
    pending.

- name: rocksdb_min_log_number_to_keep
  introducedIn: "3.6.1"
  help: |
    Minimum number of RocksDB log files to keep.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-min-log-number-to-keep".
    It shows the minimum log number of the log files that should be kept.

- name: rocksdb_num_deletes_active_mem_table
  introducedIn: "3.6.1"
  help: |
    Number of deletes in active RocksDB memtable.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-num-deletes-active-mem-table".
    It shows the total number of delete entries in the active memtable,
    summed over all column families.

- name: rocksdb_num_deletes_imm_mem_tables
  introducedIn: "3.6.1"
  help: |
    Number of deletes in unflushed immutable RocksDB memtables.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-num-deletes-imm-mem-tables".
    It shows the total number of delete entries in the unflushed immutable
    memtables, summed over all column families.

- name: rocksdb_num_entries_active_mem_table
  introducedIn: "3.6.1"
  help: |
    Number of entries in the active RocksDB memtable.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-num-entries-active-mem-table".
    It shows the total number of entries in the active memtable,
    summed over all column families.

- name: rocksdb_num_entries_imm_mem_tables
  introducedIn: "3.6.1"
  help: |
    Number of entries in unflushed immutable RocksDB memtables.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric
    "rocksdb-num-entries-imm-mem-tables".
    It shows the total number of entries in the unflushed immutable memtables,
    summed over all column families.

- name: rocksdb_num_files_at_level0
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 0.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 0 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level1
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 1.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 1 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level2
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 2.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 2 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level3
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 3.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 3 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level4
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 4.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 4 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level5
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 5.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 5 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_files_at_level6
  introducedIn: "3.6.1"
  help: |
    Number of RocksDB files at level 6.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric reports the number of files at level 6 in the log structured
    merge tree of RocksDB.

- name: rocksdb_num_immutable_mem_table
  introducedIn: "3.6.1"
  help: |
    Number of unflushed immutable RocksDB memtables.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "num-immutable-mem-table",
    which shows the number of immutable memtables that have not yet been
    flushed. This value is the sum over all column families.
  
    Memtables are sorted tables of key/value pairs which begin
    to be built up in memory. At some stage they are closed and become
    immutable, and some time later they are flushed to disk.

- name: rocksdb_num_immutable_mem_table_flushed
  introducedIn: "3.6.1"
  help: |
    Number of flushed immutable RocksDB memtables.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "num-immutable-mem-table-flushed",
    which shows the number of immutable memtables that have already been
    flushed. This value is the sum over all column families.
  
    Memtables are sorted tables of key/value pairs which begin
    to be built up in memory. At some stage they are closed and become
    immutable, and some time later they are flushed to disk.

- name: rocksdb_num_live_versions
  introducedIn: "3.6.1"
  help: |
    Number of live RocksDB versions.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-num-live-versions".
    It shows the number of live versions. `Version` is an internal data
    structure. See `version_set.h` in the RocksDB source for details. More
    live versions often mean more SST files are held from being deleted,
    by iterators or unfinished compactions. This number is the number
    summed up over all column families.

- name: rocksdb_num_running_compactions
  introducedIn: "3.6.1"
  help: |
    Number of running RocksDB compactions.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-num-running-compactions".
    It shows the number of currently running compactions.

- name: rocksdb_num_running_flushes
  introducedIn: "3.6.1"
  help: |
    Number of running RocksDB flushes.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-num-running-flushes".
    It shows the number of currently running flushes.

- name: rocksdb_num_snapshots
  introducedIn: "3.6.1"
  help: |
    Number of unreleased RocksDB snapshots.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-num-snapshots".
    It shows the number of unreleased snapshots of the database.

- name: rocksdb_oldest_snapshot_time
  introducedIn: "3.6.1"
  help: |
    Timestamp of oldest unreleased RocksDB snapshot.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-oldest-snapshot-time".
    It shows a number representing the Unix timestamp of the oldest
    unreleased snapshot.

- name: rocksdb_prunable_wal_files
  introducedIn: "3.8.2"
  help: |
    Number of prunable RocksDB WAL files in the archive.
  unit: number
  type: gauge
  category: RocksDB
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the total number of RocksDB WAL files in the
    "archive" subdirectory that can be pruned. These are WAL files that
    can be pruned by a background thread to reclaim disk space.

- name: rocksdb_read_only
  introducedIn: "3.8.1"
  help: |
    RocksDB metric "background-errors".
  unit: number
  type: gauge
  category: RocksDB
  complexity: simple
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric indicates whether RocksDB currently is in read-only
    mode, due to a background error. If RocksDB is in read-only mode,
    this metric will have a value of "1". When in read-only mode, all
    writes into RocksDB will fail. When RocksDB is in normal operations
    mode, this metric will have a value of "0".
  troubleshoot: |
    If this value is non-zero, it means that all write operations in
    RocksDB will fail until the RocksDB background error is resolved.
    The arangod server logfile should show more details about the exact
    errors that are happening, so logs should be inspected first.
    RocksDB can set a background error when some I/O operation fails. 
    This is often due to disk space usage issues, so often either freeing 
    disk space or increasing the disk capacity will help.
    Under some conditions, RocksDB can automatically resume from the 
    background error and go back into normal operations. However, if the
    background error happens during certain RocksDB operations, it cannot
    resume operations automatically, so the instance will need a manual
    restart after the error condition is removed.

- name: rocksdb_size_all_mem_tables
  introducedIn: "3.6.1"
  help: |
    Approximate size of all RocksDB memtables.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-size-all-mem-tables".
    It shows the approximate size of all active, unflushed immutable, and
    pinned immutable memtables in bytes, summed over all column families.

- name: rocksdb_total_disk_space
  introducedIn: "3.8.0"
  help: |
    Used disk space in bytes on volume used by RocksDB.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric shows the currently used disk space in bytes on the volume
    which is used by RocksDB. Since RocksDB does not like out of disk
    space scenarios, please make sure that there is enough free disk space
    available at all times! Note that this metric is only available/populated on some platforms.

- name: rocksdb_total_inodes
  introducedIn: "3.8.0"
  help: |
    Number of used inodes on the volume used by RocksDB.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric shows the currently used number of inodes on the disk volume
    used by RocksDB. Since RocksDB does not like out of disk space
    scenarios, please make sure that there are enough free inodes available
    at all times! Note that this metric is only available/populated on some platforms.

- name: rocksdb_total_sst_files_size
  introducedIn: "3.6.1"
  help: |
    Size of all RocksDB SST files.
  unit: bytes
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exhibits the RocksDB metric "rocksdb-total-sst-files-size".
    It shows the total size in bytes of all SST files, summed over all
    column families.

- name: rocksdb_wal_pruning_active
  introducedIn: "3.8.2"
  help: |
    Whether or not the pruning of archived RocksDB WAL files is currently
    activated.
  unit: number
  type: gauge
  category: RocksDB
  complexity: medium
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric contains a value of 0 if the pruning of archived RocksDB WAL
    files is not activated, and 1 if it is activated.
    WAL file pruning is normally deactivated for the first few minutes after
    an instance is started, so that other instances in the cluster can start
    replicating from the instance before all archived WAL files are deleted.
    The value should flip from 0 to 1 a few minutes after server start.

- name: rocksdb_wal_sequence
  introducedIn: "3.8.5"
  help: |
    Current RocksDB WAL sequence number.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exposes the current RocksDB WAL sequence number. Any
    write operations into the database will increase the sequence number.

- name: rocksdb_wal_sequence_lower_bound
  introducedIn: "3.8.2"
  help: |
    RocksDB sequence number until which the background sync thread
    has caught up.
  unit: number
  type: gauge
  category: RocksDB
  complexity: advanced
  exposedBy:
    - dbserver
    - agent
    - single
  description: |
    This metric exposes the RocksDB WAL sequence number until which the
    ArangoDB background sync thread has fully caught up to. The value exposed
    here should be monotically increasing and always progress if there are
    write operations executing.

